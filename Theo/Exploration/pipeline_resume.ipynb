{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Premier pipeline résumé\r\n",
    "\r\n",
    "vérification que chaque étape marche, donc plus détaillé, avec chaque étape de fonction"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install gensim==3.8.3\r\n",
    "!pip install unidecode\r\n",
    "!pip install torch\r\n",
    "!pip install sentencepiece\r\n",
    "!pip install transformers==4.5.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from joblib.parallel import cpu_count\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "import pickle\r\n",
    "import time\r\n",
    "import functools\r\n",
    "import operator\r\n",
    "from joblib import Parallel,delayed\r\n",
    "from functools import partial\r\n",
    "import sentencepiece as spm \r\n",
    "import psutil\r\n",
    "from tqdm import tqdm\r\n",
    "import pickle\r\n",
    "import os\r\n",
    "import re\r\n",
    "from unidecode import unidecode\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import gensim\r\n",
    "\r\n",
    "from fats import BERTScore,TextRank,Random_summary,Lead_3,SMHA_Linear_classifier\r\n",
    "from fats import Make_Extractive,Word_Cleaning, Make_Embedding"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "base=pd.read_csv('MLSUM_fr_val.csv',sep=\";\")\r\n",
    "Paragraphes= base.iloc[0,1].split('.') #introduisez ici une suite de phrases non-nettoyées dans une liste\r\n",
    "\r\n",
    "# Paragraphes = [ phrase1, phrase2, ..., phraseN ]\r\n",
    "#Paragraphes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "WC=Word_Cleaning(n_jobs=1,sentence=True,threshold=True,seuil=2,lemma=False,seuil_carac=3)\r\n",
    "Paragraphes=WC.remove_empty(Paragraphes)\r\n",
    "text=WC.make_documents(Paragraphes)\r\n",
    "text=WC.remove_empty(text)\r\n",
    "#text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "W2V=gensim.models.Word2Vec.load(\"W2V_all.model\")\r\n",
    "\r\n",
    "from transformers import CamembertTokenizer, CamembertModel, CamembertConfig\r\n",
    "tok=CamembertTokenizer(\"MLSUM_tokenizer.model\")\r\n",
    "\r\n",
    "ME=Make_Extractive(cpu=1)\r\n",
    "#sentence=ME.make_w2v_sentences(text)\r\n",
    "#text=Parallel(n_jobs=cpu_max)(delayed(ME.make_splitting)(s) for s in text)\r\n",
    "\r\n",
    "dico=ME.make_encoding(text,tokenizer='MLSUM_tokenizer.model',voc_size=12000,split=1,training=False)\r\n",
    "input_ids=dico['input']\r\n",
    "att_mask=dico['mask']\r\n",
    "camem=CamembertModel.from_pretrained(\"camembert-base\")\r\n",
    "ME=Make_Embedding(tok,cpu=1)\r\n",
    "embeddings=ME.emb_phrase(input_ids,att_mask,camem)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from transformers import CamembertTokenizer, CamembertModel, CamembertConfig\r\n",
    "tok=CamembertTokenizer(\"MLSUM_tokenizer.model\")\r\n",
    "ME=Make_Embedding(tok,cpu=1)\r\n",
    "\r\n",
    "dico=ME.make_tokens(text,cpu=1)\r\n",
    "dico.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def emb_phrase(input_id,att_mask,cam):\r\n",
    "    embedding=cam(torch.tensor(input_id).squeeze(1),torch.tensor(att_mask).squeeze(1))\r\n",
    "    return embedding.last_hidden_state.mean(dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "x=camem(torch.tensor(dico['input_ids']).squeeze(1),torch.tensor(dico['attention_mask']).squeeze(1))\r\n",
    "y=x.last_hidden_state.mean(dim=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "emb_phrase(dico['input_ids'],dico['attention_mask'],camem)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0.0227,  0.1509,  0.0521,  ..., -0.0226,  0.0191, -0.0921],\n",
       "        [ 0.0375,  0.0652, -0.1596,  ...,  0.0345,  0.0453, -0.1225],\n",
       "        [ 0.0136,  0.1050, -0.0628,  ...,  0.0289,  0.0500, -0.1180],\n",
       "        ...,\n",
       "        [-0.0235,  0.1691, -0.0033,  ...,  0.0187, -0.0276, -0.1260],\n",
       "        [-0.0235,  0.1691, -0.0033,  ...,  0.0187, -0.0276, -0.1260],\n",
       "        [-0.0235,  0.1691, -0.0033,  ...,  0.0187, -0.0276, -0.1260]],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "nphrase=2\r\n",
    "TR=TextRank(tok_path='MLSUM_tokenizer.model',cpu=1)\r\n",
    "BS=BERTScore('MLSUM_tokenizer.model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "TRB=TR.make_resume(text,'bert',k=nphrase,get_score_only=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "TRB"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[426, 334]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TRW=TR.make_resume(text,'word2vec',W2V=W2V,k=nphrase)\r\n",
    "BSR=BS.make_summary(text,k=nphrase)\r\n",
    "L3=Lead_3(text,k=2)\r\n",
    "RS=Random_summary(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}