{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch\n",
    "!pip install gensim==3.8.3\n",
    "!pip install unidecode\n",
    "!pip install sentencepiece\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from joblib.parallel import cpu_count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import functools\n",
    "import operator\n",
    "from joblib import Parallel,delayed\n",
    "from functools import partial\n",
    "import sentencepiece as spm \n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from transformers.utils.dummy_pt_objects import CamembertModel\n",
    "from transformers.utils.dummy_sentencepiece_objects import CamembertTokenizer\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "import gensim\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "from fats import BERTScore, Make_Embedding,TextRank,Random_summary,Lead_3,SMHA_Linear_classifier\n",
    "from fats import Make_Extractive\n",
    "\n",
    "os.chdir(\"/home/jovyan/work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "Paragraphes=pickle.load(open('Paragraphes.pickle','rb'))\n",
    "Paragraphes=functools.reduce(operator.iconcat, Paragraphes, [])\n",
    "\n",
    "from fats import Make_Embedding\n",
    "from transformers import CamembertTokenizer,CamembertModel\n",
    "tok=CamembertTokenizer('MLSUM_tokenizer.model')\n",
    "camem=CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "nphrase=2\n",
    "TR=TextRank(tok_path='MLSUM_tokenizer.model',cpu=1)\n",
    "BS=BERTScore('MLSUM_tokenizer.model',cpu=1)\n",
    "\n",
    "W2V=gensim.models.Word2Vec.load(\"W2V_all.model\")\n",
    "TRB=partial(TR.make_resume,type='bert',modele=camem,k=nphrase,get_score_only=True)\n",
    "TRW=partial(TR.make_resume,type='word2vec',modele=W2V,k=nphrase,get_score_only=True)\n",
    "BSR=BS.make_score\n",
    "L3=partial(Lead_3,k=nphrase)\n",
    "RS=partial(Random_summary,get_index_only=True)\n",
    "\n",
    "taille=100\n",
    "start=[]\n",
    "end=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR=TextRank(tok_path='MLSUM_tokenizer.model',cpu=1)\n",
    "e,d=TR.make_embedding_bert(Paragraphes[6],camem=camem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/23508 [00:14<22:39:13,  3.47s/it]"
     ]
    }
   ],
   "source": [
    "fichiers=[i for i in os.listdir() if 'BSR_sortie' in i]\n",
    "a=[] if len(fichiers)==0 else pickle.load(open(fichiers[0],'rb'))\n",
    "for i in tqdm(range(len(a),len(Paragraphes))):\n",
    "    x=BSR(Paragraphes[i])\n",
    "    a.append(x)\n",
    "    del x\n",
    "    gc.collect()\n",
    "    if i%10==0:\n",
    "        pickle.dump(a,open(\"BSR_sortie.pickle\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start.append(time.time())\n",
    "TRB_sortie=Parallel(2)(delayed(TRB)(i) for i in tqdm(Paragraphes[:taille]))\n",
    "# TRB_sortie=TRB(Paragraphes[0])\n",
    "pickle.dump(TRB_sortie,open('test/TRB_sortie.pickle','wb'))\n",
    "end.append(time.time())\n",
    "print(\"TRB :\",round((end[-1]-start[-1])/60,2),\"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRB_sortie=TRB(Paragraphes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achevé : 0.0 %\n",
      "Achevé : 1.05 %\n"
     ]
    }
   ],
   "source": [
    "TRB_sortie_2=[] #pickle.load(open('TRB_sortie.pickle','rb'))\n",
    "longueur=[]\n",
    "for i in range(len(TRB_sortie_2),len(Paragraphes)):\n",
    "    longueur.append(len(Paragraphes[i]))\n",
    "    start.append(time.time())\n",
    "    TRB_sortie_2.append(TRB(Paragraphes[i]))\n",
    "    end.append(time.time())\n",
    "    if i%250==0:\n",
    "        print(\"Achevé :\",round((i/len(Paragraphes))*100,2),\"%\")\n",
    "        pickle.dump(TRB_sortie_2,open(\"TRB_sortie.pickle\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSR_sortie=pickle.load(open('BSR_sortie.pickle','rb'))\n",
    "erreur=pickle.load(open('BSR_erreur.pickle','rb'))\n",
    "BSR_sortie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Unexpected error: (<class 'ValueError'>, ValueError('only one element tensors can be converted to Python scalars'), <traceback object at 0x7fafd6866f50>)\n",
      "Achevé : 0.0 %\n",
      "Nombre d'erreurs : 0.0 %\n",
      "1\n",
      "Unexpected error: (<class 'KeyboardInterrupt'>, KeyboardInterrupt(), <traceback object at 0x7fafd5c77d70>)\n",
      "2\n",
      "Unexpected error: (<class 'ValueError'>, ValueError('only one element tensors can be converted to Python scalars'), <traceback object at 0x7fafd5c40870>)\n"
     ]
    }
   ],
   "source": [
    "BSR_sortie=[]\n",
    "erreur=[]\n",
    "for i in range(len(Paragraphes)):\n",
    "    try:\n",
    "        x=BSR(Paragraphes[i])\n",
    "        BSR_sortie.append(x)\n",
    "    except:\n",
    "        print(i)\n",
    "        print(\"Unexpected error:\", sys.exc_info())\n",
    "        erreur.append(i)\n",
    "    if i%250==0:\n",
    "        print(\"Achevé :\",round((i/len(Paragraphes))*100,2),\"%\")\n",
    "        pickle.dump(BSR_sortie,open(\"BSR_sortie.pickle\",'wb'))\n",
    "        pickle.dump(erreur,open(\"BSR_erreur.pickle\",'wb'))\n",
    "        print(\"Nombre d'erreurs :\",round(len(erreur)/len(Paragraphes)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9443, 0.9410, 0.9669, 0.6170, 0.9655, 0.9092, 0.9209, 0.9330, 0.7975,\n",
       "        0.9526, 0.9336, 0.8616, 0.7908, 0.9259, 0.9285],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSR(Paragraphes[torch.randint(len(Paragraphes),(1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BSR_sortie=pickle.load(open('BSR_sortie.pickle','rb'))\n",
    "len(BSR_sortie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0869313398996989\n",
      "0.07791940172513326\n",
      "0.08362084759606254\n",
      "0.09673363069693247\n",
      "0.10170523166656494\n"
     ]
    }
   ],
   "source": [
    "import fats\n",
    "for i in range(1,6):\n",
    "    s=time.time()\n",
    "    resu=TR.make_resume(Paragraphes[:i],\n",
    "                     cpu=1,\n",
    "                     type_='TextRankBert',\n",
    "                     k=2,\n",
    "                     modele=camem,\n",
    "                     tok=\"MLSUM_tokenizer.model\",\n",
    "                     get_score_only=True)\n",
    "    print((time.time()-s)/60/i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3], [0, 10]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fats\n",
    "resu=fats.Resume(Paragraphes[0:2],\n",
    "                     DL=False,\n",
    "                     cpu=1,\n",
    "                     type_='TextRankBert',k=2,modele=camem,\n",
    "                     tok=\"MLSUM_tokenizer.model\",get_score_only=True)\n",
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2801"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendu=pickle.load(open('TRB_sortie.pickle','rb'))\n",
    "len(rendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9098 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 198/9098 [38:13<23:15:10,  9.41s/it] "
     ]
    }
   ],
   "source": [
    "rendu=pickle.load(open('TRB_sortie.pickle','rb'))#[] if \n",
    "print(len(rendu))\n",
    "import fats\n",
    "pas=1\n",
    "\n",
    "for i in tqdm(range(len(rendu),int(len(Paragraphes)/(pas+1)))):\n",
    "    resu=fats.Resume(Paragraphes[(i*2):(i+pas)*2],\n",
    "                     DL=False,\n",
    "                     cpu=1,\n",
    "                     type_='TextRankBert',k=2,modele=camem,\n",
    "                     tok=\"MLSUM_tokenizer.model\",get_score_only=True)\n",
    "    rendu.append(resu)\n",
    "               \n",
    "    if i%100==0:\n",
    "        pickle.dump(rendu,open('TRB_sortie.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
