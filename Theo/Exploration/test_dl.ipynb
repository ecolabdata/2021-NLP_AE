{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entraînement des modèles\r\n",
    "\r\n",
    "Première simplification du notebook d'entraînement Deep Learning, avec tests et différents débugging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch.nn as nn\r\n",
    "import sklearn\r\n",
    "import torch\r\n",
    "import pickle\r\n",
    "import os\r\n",
    "import time\r\n",
    "from tqdm import tqdm\r\n",
    "from joblib import Parallel, delayed\r\n",
    "from torch.autograd import Variable\r\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "device = torch.device(\"cuda\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_dataset=pickle.load(open('train_dataset_1.pickle','rb'))\r\n",
    "\r\n",
    "output_=torch.stack([train_dataset[i][-1] for i in range(len(train_dataset))])\r\n",
    "mask_cls_=torch.stack([train_dataset[i][-2] for i in range(len(train_dataset))])\r\n",
    "output_2=torch.mul(torch.div(output_-torch.min(output_),torch.max(output_)-torch.min(output_)),mask_cls_)\r\n",
    "output_2\r\n",
    "\r\n",
    "K=1000\r\n",
    "train_2=TensorDataset(torch.stack([train_dataset[i][0] for i in range(K)]),\r\n",
    "                      torch.stack([train_dataset[i][1] for i in range(K)]),\r\n",
    "                      torch.stack([train_dataset[i][2] for i in range(K)]),\r\n",
    "                      torch.stack([train_dataset[i][3] for i in range(K)]),\r\n",
    "                      output_2[:K])\r\n",
    "\r\n",
    "batch_size=int(1024/8/8)\r\n",
    "print(batch_size)\r\n",
    "\r\n",
    "dataloader_2 = DataLoader(\r\n",
    "            train_2,\r\n",
    "            sampler = RandomSampler(train_2),\r\n",
    "            batch_size = batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "dataloader_2=pickle.load(open('train_loader_2.pickle','rb'))\r\n",
    "print(\"Nombre de batchs :\",len(dataloader_2))\r\n",
    "for _,batch in enumerate(dataloader_2):\r\n",
    "    print(\"Taille du batch :\",len(batch[0]))\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nombre de batchs : 2095\n",
      "Taille du batch : 64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "for batch in dataloader_2:\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "batch[0][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([    5,    39,  2486,   379,  1678,  2878, 11355,   593,  8329,     6,\n",
       "            5,   460, 11824,   757,  1079,    75,   952,    39,  2708,   379,\n",
       "         9507,  1555, 11049,    87,  1567,  1678,  2878, 11355,  1206,  4353,\n",
       "         7974,   339,   857,     6,     5,   209,  2080,  6867,  2479,  4548,\n",
       "         2751,    39,  3054,  3710,  8601,  3508,  1678,  2071,   795,    99,\n",
       "          355,  8211,   379,  1678,   951,  7709,  1106, 11980,  2370,     6,\n",
       "            5,   293,  8021,   131,   695,   243,  2660,  2758,  3112,  3508,\n",
       "           98,  1206,   423,  1032,   232,   720,  1099,     6,     5,  1678,\n",
       "         2878, 11355,  4272,   991,    59,   378,   638,   939,   238,   177,\n",
       "         6060,   249,    75,  1678,  5590,    98,   108,  8217,  8519,    40,\n",
       "         2836,   167,  2298,  1047,  2310,    99,    40,  6794,    98,   354,\n",
       "         8371,  5395,  2467,  1219,   951,  1106, 11980,  2370,  3306,    94,\n",
       "         2134,  8793,   722,    87,  8329,  7645,   243,  2298,  1047,     6,\n",
       "            5,    40,  9947,  1289,  1706,  9081,  2174,  1985,    75,  3330,\n",
       "         2902,    99,    40,  5955,  5039,     7,     6,     5,   182,    79,\n",
       "         1913,  1322,    82,  2466,  4544,     6,     5,  1218,    79,  3499,\n",
       "           39,   766,   262,  2836,    98,   931,  4871,  9222,     6,     5,\n",
       "          950,   108,  5453,    94,  9781,    82,   348,    98,  2377,  1270,\n",
       "          659,  1040,     6,     5,   293,   606,    88,   131,   108,    40,\n",
       "         3103,    40,  3456,    98,   199,   542,  4367,   182,   588,   759,\n",
       "         1248,   116,   308,   660,    98,   177,   273,    59,  1456,  2878,\n",
       "        11355,     6,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "            1,     1])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class F1_score:\r\n",
    "    \"\"\"\r\n",
    "    Class for f1 calculation in Pytorch.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self):#, average: str = 'weighted'):\r\n",
    "        \"\"\"\r\n",
    "        Init.\r\n",
    "\r\n",
    "        Args:\r\n",
    "            average: averaging method\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        #self.average = average\r\n",
    "        #if average not in [None, 'micro', 'macro', 'weighted']:\r\n",
    "         #   raise ValueError('Wrong value of average parameter')\r\n",
    "    @staticmethod\r\n",
    "    def true_positive_mean(x,y) -> torch.tensor:\r\n",
    "        '''\r\n",
    "        Caclul le nombre moyen de vrai positif de la prediction x par rapport aux labels y (binaires).\r\n",
    "        '''\r\n",
    "        tp=torch.mul(x,y).sum()\r\n",
    "        tpm=torch.div(tp,y.shape[0])\r\n",
    "        return tpm\r\n",
    "    @staticmethod\r\n",
    "    def false_positive_mean(x,y) -> torch.tensor:\r\n",
    "        '''\r\n",
    "        Caclul le nombre moyen de faux négatif de la prediction x par rapport aux labels y (binaires).\r\n",
    "        '''\r\n",
    "        device=y.device\r\n",
    "        fp=torch.sub(x,y)\r\n",
    "        fp=torch.max(fp,torch.tensor([0.]).to(device))\r\n",
    "        fp=fp.sum().float()\r\n",
    "        fpm=torch.div(fp,y.shape[0])\r\n",
    "        return fpm\r\n",
    "    @staticmethod\r\n",
    "    def false_negative_mean(x,y) -> torch.tensor:\r\n",
    "        '''\r\n",
    "        Caclul le nombre moyen de faux négatif de la prediction x par rapport aux labels y (binaires).\r\n",
    "        '''\r\n",
    "        fn=torch.sub(y,x)\r\n",
    "        device=y.device\r\n",
    "        fn=torch.max(fn,torch.tensor([0.]).to(device))\r\n",
    "        fn=fn.sum().float()\r\n",
    "        fnm=torch.div(fn,y.shape[0])\r\n",
    "        return fnm\r\n",
    "    #@staticmethod\r\n",
    "    def precision(self,x,y) -> torch.tensor:\r\n",
    "        device=y.device\r\n",
    "        tp=self.true_positive_mean(x,y)\r\n",
    "        fp=self.false_positive_mean(x,y)\r\n",
    "        if (tp+fp)!=0:\r\n",
    "            prec=torch.div(tp,(tp+fp))\r\n",
    "            return prec\r\n",
    "        else:\r\n",
    "            return torch.tensor(0.).to(device)\r\n",
    "\r\n",
    "    def recall(self,x,y) -> torch.tensor:\r\n",
    "        tp=self.true_positive_mean(x,y)\r\n",
    "        fn=self.false_negative_mean(x,y)\r\n",
    "        rec=torch.div(tp,(tp+fn))\r\n",
    "        return rec\r\n",
    "    def __call__(self,x,y) -> torch.tensor:\r\n",
    "        device=y.device\r\n",
    "        rec=self.recall(x,y)\r\n",
    "        prec=self.precision(x,y)\r\n",
    "        f1=torch.mul(rec,prec)\r\n",
    "        f1=torch.mul(2,f1)\r\n",
    "        f1=torch.div(f1,prec+rec)\r\n",
    "        if (prec+rec)!=0:\r\n",
    "            return f1#prec,rec,\r\n",
    "        else:\r\n",
    "            return torch.tensor(0.).to(device)#prec,rec,\r\n",
    "\r\n",
    "        \r\n",
    "class Weighted_Loss:\r\n",
    "    '''\r\n",
    "    Fonction permettant de calculer la fonction de perte Mean Absolute Error mais pondérée par des poids.\r\n",
    "    '''\r\n",
    "    def __init__(self,weight,loss_type='L1',binary=True):\r\n",
    "        '''\r\n",
    "        On initialise notre fonction de perte :\r\n",
    "        @weight : les poids que vous voulez pour chaque classe (dim=nombre de classe)\r\n",
    "        '''\r\n",
    "        self.weights=weight\r\n",
    "        self.loss_type=loss_type\r\n",
    "        self.binary=binary\r\n",
    "        \r\n",
    "    def Weighted_L1(self,y_hat,y) -> torch.Tensor:\r\n",
    "        '''\r\n",
    "        On calcule la fonction :\r\n",
    "        @y_hat : les prédictions du modèle\r\n",
    "        @y : les vraies valeurs\r\n",
    "        \r\n",
    "        Attention, dim(y_hat)==dim(y)\r\n",
    "        '''\r\n",
    "        if y_hat.shape!=y.shape:\r\n",
    "            raise ValueError(\"Attention, les deux inputs n'ont pas la même dimension !\")\r\n",
    "        #On met les deux tensors sur le même service (ici GPU)\r\n",
    "        device_yhat=y_hat.device\r\n",
    "        device_y=y.device\r\n",
    "        if device_yhat!=device_y:\r\n",
    "            y.to(device_yhat)\r\n",
    "        \r\n",
    "        w=torch.repeat_interleave(self.weights[0].clone().detach(),y.shape[1])\r\n",
    "        w=w.repeat(y.shape[0],1)\r\n",
    "                \r\n",
    "        if self.binary:\r\n",
    "            w[torch.arange(y.shape[0],dtype=torch.long).unsqueeze(1),torch.topk(y,3)[1]]=self.weights[1]\r\n",
    "        \r\n",
    "        else: #On surpondère les indices qui représentent les phrases, puisque c'est cela que le modèle doit prédire\r\n",
    "            x=torch.nonzero(y!=torch.tensor(0))#.nonzero()\r\n",
    "            x_2=torch.index_select(x,1,torch.tensor(1).to(device_yhat)).reshape(-1).to(device_yhat)\r\n",
    "            x_1=torch.nonzero(x_2==0).to(device_yhat)#.nonzero()\r\n",
    "            sha=torch.arange(y.shape[0],dtype=torch.long).unsqueeze(1).to(device_yhat)\r\n",
    "            \r\n",
    "            for k in range(len(x_1)):\r\n",
    "                if k<(len(x_1)-1):\r\n",
    "                    w[sha[k],x_2[x_1[k]:x_1[k+1]]]=self.weights[1]\r\n",
    "                else:\r\n",
    "                    w[sha[k],x_2[x_1[k]:]]=self.weights[1]\r\n",
    "               \r\n",
    "        sum_weights=w.sum()\r\n",
    "        w=w.to(device_yhat)\r\n",
    "        sum_weights=sum_weights.to(device_yhat)\r\n",
    "        errors=torch.sub(y,y_hat)\r\n",
    "        errors=torch.abs(errors)\r\n",
    "        weighted_errors=torch.mul(w,errors)\r\n",
    "        sum_weighted_errors=weighted_errors.sum()\r\n",
    "        WMAE=torch.div(sum_weighted_errors,sum_weights)\r\n",
    "        #WMAE.requires_grad=True\r\n",
    "        return Variable(WMAE,requires_grad=True)#,sum_weighted_errors,sum_weights\r\n",
    "    \r\n",
    "    def Weighted_Sum(self,y_hat,y) -> torch.Tensor:\r\n",
    "        '''\r\n",
    "        Calcule la somme pondérée de la différence de la prédiction du modèle et du vecteur cible.\r\n",
    "        '''\r\n",
    "        if y_hat.shape!=y.shape:\r\n",
    "            raise ValueError(\"Attention, les deux inputs n'ont pas la même dimension !\")\r\n",
    "        \r\n",
    "        #On met les deux tensors sur le même service (ici GPU)\r\n",
    "        device_yhat=y_hat.device\r\n",
    "        device_y=y.device\r\n",
    "        if device_yhat!=device_y:\r\n",
    "            y.to(device_yhat)\r\n",
    "        \r\n",
    "        w=torch.repeat_interleave(self.weights[0].clone().detach(),y.shape[1])\r\n",
    "        w=w.repeat(y.shape[0],1)\r\n",
    "        \r\n",
    "        if self.binary:\r\n",
    "            w[torch.arange(y.shape[0],dtype=torch.long).unsqueeze(1),torch.topk(y,3)[1]]=self.weights[1]\r\n",
    "        \r\n",
    "        else: #On surpondère les indices qui représentent les phrases, puisque c'est cela que le modèle doit prédire\r\n",
    "            x=torch.nonzero(y!=torch.tensor(0))#.nonzero()\r\n",
    "            x_2=torch.index_select(x,1,torch.tensor(1).to(device_yhat)).reshape(-1).to(device_yhat)\r\n",
    "            x_1=torch.nonzero(x_2==0).to(device_yhat)#.nonzero()\r\n",
    "            sha=torch.arange(y.shape[0],dtype=torch.long).unsqueeze(1).to(device_yhat)\r\n",
    "            \r\n",
    "            for k in range(len(x_1)):\r\n",
    "                if k<(len(x_1)-1):\r\n",
    "                    w[sha[k],x_2[x_1[k]:x_1[k+1]]]=self.weights[1]\r\n",
    "                else:\r\n",
    "                    w[sha[k],x_2[x_1[k]:]]=self.weights[1]\r\n",
    "                    \r\n",
    "        w=w.to(device_yhat)\r\n",
    "        y_diff=torch.abs(torch.sub(y,y_hat))\r\n",
    "        y_diff_pond=torch.mul(y_diff,w)\r\n",
    "        sum_y_diff_pon=torch.div(torch.sum(y_diff_pond),y_hat.shape[0])\r\n",
    "        return Variable(sum_y_diff_pon,requires_grad=True)\r\n",
    "    \r\n",
    "    def __call__(self,y_hat,y) -> torch.Tensor:\r\n",
    "        if self.loss_type=='L1':\r\n",
    "            loss=self.Weighted_L1(y_hat,y)\r\n",
    "            return loss\r\n",
    "        elif self.loss_type=='sum':\r\n",
    "            loss=self.Weighted_Sum(y_hat,y)\r\n",
    "            return loss\r\n",
    "        else:\r\n",
    "            raise ValueError(\"Attention, veuillez bien spécifier un type de perte.\\nSeules les valeurs 'L1' ou 'sum' sont acceptées.\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from transformers import CamembertModel,CamembertConfig,AdamW\r\n",
    "camem1=CamembertModel(CamembertConfig())\r\n",
    "camem2=CamembertModel.from_pretrained(\"camembert-base\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Simple_Classifier(nn.Module):\r\n",
    "    def __init__(self, hidden_size):\r\n",
    "        super(Simple_Classifier, self).__init__()\r\n",
    "        self.linear1 = nn.Linear(hidden_size, 1)\r\n",
    "        self.relu=nn.LeakyReLU(negative_slope= 0.01)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x.requires_grad_(True)\r\n",
    "        h = self.linear1(x).squeeze(-1)\r\n",
    "        sent_scores = self.relu(h)\r\n",
    "        return sent_scores.squeeze(-1)\r\n",
    "\r\n",
    "class Multi_Linear_Classifier(nn.Module):\r\n",
    "    def __init__(self, hidden_size):\r\n",
    "        super(Multi_Linear_Classifier, self).__init__()\r\n",
    "        self.linear1 = nn.Linear(hidden_size, int(hidden_size/2))\r\n",
    "        self.linear2 = nn.Linear(int(hidden_size/2),int(hidden_size/6))\r\n",
    "        self.linear3 = nn.Linear(int(hidden_size/6),1)\r\n",
    "        self.Lrelu=nn.LeakyReLU(negative_slope= 0.01)\r\n",
    "        self.softmax=nn.Softmax(dim=-1)\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, x):#, mask_cls):\r\n",
    "        x.requires_grad_(True)\r\n",
    "        h = self.linear1(x).squeeze(-1)\r\n",
    "        h = self.softmax(h)#self.Lrelu(h) #* mask_cls.float()\r\n",
    "        h = self.linear2(h)\r\n",
    "        h = self.softmax(h)#self.Lrelu(h)\r\n",
    "        h = self.linear3(h)\r\n",
    "        #h = self.softmax(h)#self.Lrelu(h)\r\n",
    "        return h.squeeze(-1)\r\n",
    "    \r\n",
    "\r\n",
    "class SMHA_classifier(nn.Module):\r\n",
    "    def __init__(self, size,nhead):\r\n",
    "        super(SMHA_classifier, self).__init__()\r\n",
    "        self.MHA = nn.MultiheadAttention(size[1], nhead)\r\n",
    "        self.LReLu=nn.LeakyReLU(negative_slope= 0.01)\r\n",
    "        self.sigmoid = nn.Sigmoid()\r\n",
    "        self.LN=nn.LayerNorm(size)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x.requires_grad_(True)\r\n",
    "        h,weights = self.MHA(x,x,x)\r\n",
    "        normalized_h=self.LN(h)\r\n",
    "        sent_scores = self.LReLu(normalized_h) #* mask_cls.float()\r\n",
    "        return sent_scores.mean(dim=2)\r\n",
    "    \r\n",
    "class SMHA_Linear_classifier(nn.Module):\r\n",
    "    def __init__(self, size,nhead,hidden_size):\r\n",
    "        super(SMHA_Linear_classifier, self).__init__()\r\n",
    "        self.MHA = nn.MultiheadAttention(size[1], nhead)\r\n",
    "        self.LReLu=nn.LeakyReLU(negative_slope= 0.01)\r\n",
    "        self.sigmoid = nn.Sigmoid()\r\n",
    "        self.LN=nn.LayerNorm(size)\r\n",
    "        self.linear1 = nn.Linear(hidden_size, int(hidden_size/2))\r\n",
    "        self.linear2 = nn.Linear(int(hidden_size/2),int(hidden_size/6))\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x.requires_grad_(True)\r\n",
    "        h,weights = self.MHA(x,x,x)\r\n",
    "        h=self.LN(h)\r\n",
    "        h=self.linear1(h)\r\n",
    "        h=self.LReLu(h)\r\n",
    "        h=self.linear2(h)\r\n",
    "        sent_scores = self.LReLu(h) #* mask_cls.float()\r\n",
    "        return sent_scores.mean(dim=2) \r\n",
    "    \r\n",
    "\r\n",
    "class Net(nn.Module):\r\n",
    "    def __init__(self,k1,k2,k3,s1,s2,s3):\r\n",
    "        super().__init__()\r\n",
    "        self.conv1 = nn.Conv1d(512, 512, kernel_size=k1,stride=s1)\r\n",
    "        self.pool = nn.MaxPool1d(k2, s2)\r\n",
    "        self.conv2 = nn.Conv1d(512, 512, kernel_size=k3,stride=s3)\r\n",
    "        self.dim=int((768-k1)/s1)+1\r\n",
    "        self.dim=int((self.dim-(k2-1)-1)/s2+1)\r\n",
    "        self.dim=int((self.dim-k3)/s3)+1\r\n",
    "        self.fc1 = nn.Linear(self.dim, int(self.dim/2))\r\n",
    "        self.fc2 = nn.Linear(int(self.dim/2), int(self.dim/8))\r\n",
    "        self.fc3 = nn.Linear(int(self.dim/8), 1)\r\n",
    "        self.LReLu=nn.LeakyReLU(negative_slope= 0.01)\r\n",
    "        self.softmax=nn.Softmax(dim=-1)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x.requires_grad_(True)\r\n",
    "        x = self.pool(self.LReLu(self.conv1(x)))\r\n",
    "        x =self.LReLu(self.conv2(x))\r\n",
    "        #x = torch.flatten(x, 1) # flatten all dimensions except batch\r\n",
    "        x = self.LReLu(self.fc1(x))\r\n",
    "        x = self.LReLu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        #x=self.softmax(x)\r\n",
    "        return x.flatten(1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vérification de fonctionnement des modèles et optimiseurs "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "mlc=Multi_Linear_Classifier(camem2.config.hidden_size)\r\n",
    "mlc_optimizer_SGD=optim.SGD(mlc.parameters(), lr=0.001, momentum=0.09)\r\n",
    "mlc_optimizer_Adam=optim.AdamW(convnet.parameters(), lr=0.009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "\r\n",
    "slc=Simple_Classifier(camem2.config.hidden_size)\r\n",
    "slc_optimizer=optim.AdamW(slc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "#SGD(slc.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "att_c=SMHA_classifier(torch.Size([512,768]),8)\r\n",
    "att_c_optimizer=optim.SGD(att_c.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "att_lin_c=SMHA_Linear_classifier(torch.Size([512,768]),8,768)\r\n",
    "att_lin_c_optimizer=optim.SGD(att_lin_c.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "convnet=Net(2**8,2**6,2,2,2,2)\r\n",
    "convnet_optimizer=optim.AdamW(convnet.parameters(), lr=0.009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "#SGD(convnet.parameters(), lr=0.001, momentum=0.09)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input=torch.rand(16,512,768).to(device)\r\n",
    "output=torch.rand(16,512).to(device)\r\n",
    "\r\n",
    "for m,o in zip([mlc,slc,att_c,att_lin_c,convnet],[mlc_optimizer_Adam,slc_optimizer,att_c_optimizer,att_lin_c_optimizer,convnet_optimizer]):\r\n",
    "    print(\"\\n Modèle :\",str(m).split('(')[0],'\\n')\r\n",
    "    \r\n",
    "    model=m.to(device)\r\n",
    "    param1=list(model.parameters())[0].clone()\r\n",
    "\r\n",
    "    sortie=model(input)\r\n",
    "\r\n",
    "    for l in [nn.MSELoss(),loss_2,loss_3]:\r\n",
    "        ouais=l(sortie,output)\r\n",
    "        o.zero_grad()\r\n",
    "        ouais.backward(retain_graph=True)\r\n",
    "        o.step()\r\n",
    "        \r\n",
    "        param2=list(model.parameters())[0].clone()\r\n",
    "        print(\"For loss,\",l,\"Did the grad updated the weights ?\",bool(1-torch.equal(param1.data,param2.data)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "the learning rate has to be smaller for mini-batch learning, because the smaller the batch size the larger the gradient variance you have which can cause bad optimization steps when the step size is not decreased.\n",
    "\n",
    "Stochastic gradient descent usually oscillate heavily between different loss function values and would asymptotically decrease with lower step size. The convergence rate of stochastic gradient descent depends heavily on the step size [1].\n",
    "\n",
    "With full-batch gradient descent, you have the full gradient information of the batch which allows you to take a bigger step size without risking having \"bad\" optimization steps."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k=4\r\n",
    "input=torch.rand(k,16,512,768).to(device)\r\n",
    "output_ex=torch.rand(k,16,512).to(device)\r\n",
    "\r\n",
    "epochs=k\r\n",
    "#step=2\r\n",
    "\r\n",
    "#convnet=Net(2**8,2**6,2,2,2,2)\r\n",
    "#convnet_optimizer=optim.AdamW(convnet.parameters(), lr=0.009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "\r\n",
    "l=loss_3#nn.MSELoss()\r\n",
    "\r\n",
    "#model=convnet.to(device)\r\n",
    "#o=convnet_optimizer\r\n",
    "\r\n",
    "param=[]\r\n",
    "param.append(list(model.parameters())[0].clone())\r\n",
    "\r\n",
    "#loss=0\r\n",
    "model.zero_grad()\r\n",
    "\r\n",
    "for e in range(epochs):\r\n",
    "    sortie=model(input[e])\r\n",
    "\r\n",
    "    ouais=l(sortie,output_ex[e])\r\n",
    "    #loss+=ouais\r\n",
    "    ouais.backward()#retain_graph=True)\r\n",
    "    \r\n",
    "    #if e%step==0:\r\n",
    "    optimizer.step()\r\n",
    "\r\n",
    "    for par in model.parameters():\r\n",
    "        print(par.grad.data.sum())\r\n",
    "\r\n",
    "    # start debugger\r\n",
    "    #import pdb; pdb.set_trace()\r\n",
    "    print(\"\\n\")\r\n",
    "    optimizer.zero_grad()\r\n",
    "\r\n",
    "    for par in model.parameters():\r\n",
    "        print(par.grad.data.sum())\r\n",
    "\r\n",
    "    param.append(list(model.parameters())[0].clone())\r\n",
    "    z=int(e)\r\n",
    "    print(\"\\nFor epoch,\",z,\"Did the grad updated the weights ?\",bool(1-torch.equal(param[z].data,param[z+1].data)),\"\\n\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "for step, batch in enumerate(data):\r\n",
    "    input_id = batch[0]#.to(device)\r\n",
    "    mask = batch[1]#.to(device)\r\n",
    "    clss = batch[2].float().to(device)\r\n",
    "    mask_cls=batch[3]#.to(device)\r\n",
    "    output=batch[4].float().to(device)\r\n",
    "    #[list(model.parameters())[i].clone() for i in range(len(list(model.parameters())))]\r\n",
    "    param1=list(model.parameters())[0].clone()\r\n",
    "    if step>0:\r\n",
    "        break\r\n",
    "\r\n",
    "topvec=camem2(input_id,mask)\r\n",
    "topvec=topvec.last_hidden_state.to(device)\r\n",
    "\r\n",
    "sortie=model(topvec)\r\n",
    "\r\n",
    "ouais=loss(sortie,output)\r\n",
    "ouais.backward()\r\n",
    "optimizer.step()\r\n",
    "optimizer.zero_grad()\r\n",
    "\r\n",
    "param=list(model.parameters())[0].clone()\r\n",
    "print(\"Did the grad updated the weights ?\",bool(1-torch.equal(param1.data,param.data)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Did the grad updated the weights ? True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import gc\r\n",
    "def check_weights_update(model,loss,optim,dev=False):\r\n",
    "    param1=list(model.parameters())[0].clone()\r\n",
    "    input=torch.rand(torch.Size([3,512,768]))\r\n",
    "    target=torch.rand(torch.Size([3,512]))\r\n",
    "    \r\n",
    "    if dev:\r\n",
    "        input=input.to(torch.device('cuda'))\r\n",
    "        target=target.to(torch.device('cuda'))\r\n",
    "    \r\n",
    "    sortie=model(input)\r\n",
    "    optim.zero_grad()\r\n",
    "    ouais=loss(sortie,target)\r\n",
    "    ouais.backward()\r\n",
    "    optim.step()\r\n",
    "    param=list(model.parameters())[0].clone()\r\n",
    "    out=bool(1-torch.equal(param1.data,param.data))\r\n",
    "    del input,target,sortie,ouais\r\n",
    "    gc.collect()\r\n",
    "    torch.cuda.empty_cache()\r\n",
    "    return out\r\n",
    "#check_weights_update(Models[0],Loss[0],Optimizers[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.train()\r\n",
    "check_weights_update(model,loss,optimizer)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gestion mémoire (si besoin)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#del loss_train_3,optimizer,model,slc,mlc,att_c, att_lin_c,convnet\r\n",
    "del slc\r\n",
    "import gc\r\n",
    "gc.collect()\r\n",
    "torch.cuda.empty_cache()\r\n",
    "\r\n",
    "t = torch.cuda.get_device_properties(0).total_memory\r\n",
    "r = torch.cuda.memory_reserved(0) \r\n",
    "a = torch.cuda.memory_allocated(0)\r\n",
    "f = r-a  # free inside reserved\r\n",
    "r"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Définition des modèles et fonction de perte et entraînement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "mlc=Multi_Linear_Classifier(camem2.config.hidden_size)\r\n",
    "#mlc_optimizer_SGD=optim.SGD(mlc.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "#slc=Simple_Classifier(camem2.config.hidden_size)\r\n",
    "#slc_optimizer=optim.AdamW(slc.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "#SGD(slc.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "#att_c=SMHA_classifier(torch.Size([512,768]),8)\r\n",
    "#att_c_optimizer=optim.SGD(att_c.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "#att_lin_c=SMHA_Linear_classifier(torch.Size([512,768]),8,768)\r\n",
    "#att_lin_c_optimizer=optim.AdamW(att_lin_c.parameters(), lr=0.0009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "#SGD(att_lin_c.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "#convnet=Net(2**8,2**6,2,2,2,2)\r\n",
    "#convnet_optimizer=optim.AdamW(convnet.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "#SGD(convnet.parameters(), lr=0.001, momentum=0.09)\r\n",
    "\r\n",
    "score=F1_score()\r\n",
    "\r\n",
    "alpha=0.1\r\n",
    "weights=torch.Tensor([(1/(1-alpha))*1/((512-20)/512),(1/alpha)*1/((20)/512)])\r\n",
    "#weights=torch.Tensor([(1/(1-alpha))*1/((1)/512),(1/alpha)*1/((512-1)/512)])\r\n",
    "#weights=torch.Tensor([1,1])\r\n",
    "print(weights)\r\n",
    "loss_3=Weighted_Loss(weight=weights,loss_type='sum',binary=False)\r\n",
    "loss_2=Weighted_Loss(weight=weights,loss_type='L1',binary=False)\r\n",
    "loss=nn.MSELoss()#nn.L1Loss()\r\n",
    "epochs=10\r\n",
    "model=mlc.to(device)\r\n",
    "#model\r\n",
    "mlc_optimizer_Adam=optim.AdamW(model.parameters(), lr=0.009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "optimizer=mlc_optimizer_Adam\r\n",
    "data=dataloader_2\r\n",
    "\r\n",
    "model.train()\r\n",
    "print(check_weights_update(model,loss,optimizer,dev=True),check_weights_update(model,loss_2,optimizer,dev=True),check_weights_update(model,loss_3,optimizer,dev=True))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([  1.1563, 256.0000])\n",
      "True True True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Boucle d'entraînement"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model=SMHA_Linear_classifier(torch.Size([512,768]),8,768)\r\n",
    "path='SMHA_Linear_classifier.pt'\r\n",
    "model.load_state_dict(torch.load(path))\r\n",
    "model.to(device)\r\n",
    "\r\n",
    "optimizer=optim.AdamW(model.parameters(), lr=0.0009, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01)\r\n",
    "optimizer.load_state_dict(torch.load(path[:-3]+'_AdamW.pt'))\r\n",
    "\r\n",
    "model.train()\r\n",
    "check_weights_update(model,loss,optimizer,dev=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Pour enregistrer les informations de l'entraînement\r\n",
    "training_stats = []\r\n",
    "score_stat=[]\r\n",
    "\r\n",
    "#loss.requires_grad=True\r\n",
    "#pred_output={}\r\n",
    "\r\n",
    "# Boucle d'entrainement\r\n",
    "camem2.to('cpu')\r\n",
    "#model.train()\r\n",
    "#model.to(device)\r\n",
    "model.zero_grad()\r\n",
    "print(\"Entraînement du modèle :\",str(model).split('(')[0])\r\n",
    "start=time.time()\r\n",
    "\r\n",
    "for epoch in range(0, epochs):\r\n",
    "\r\n",
    "    # On initialise la loss pour cette epoque\r\n",
    "    total_train_loss = 0\r\n",
    "    total_train_loss_2 = 0\r\n",
    "    total_train_loss_3 = 0\r\n",
    "    f1_score=0\r\n",
    "    prec_score=0\r\n",
    "    #pred=[]\r\n",
    "    # On met le modele en mode 'training'\r\n",
    "    # Dans ce mode certaines couches du modele agissent differement\r\n",
    "\r\n",
    "    # Pour chaque batch\r\n",
    "    for step, batch in enumerate(tqdm(data)):\r\n",
    "\r\n",
    "        # On recupere les donnees du batch\r\n",
    "        input_id = batch[0]#.to(device)\r\n",
    "        mask = batch[1]#.to(device)\r\n",
    "        clss = batch[2].float().to(device)\r\n",
    "        mask_cls=batch[3]#.to(device)\r\n",
    "        output=batch[4].float().to(device)\r\n",
    "\r\n",
    "        param1=list(model.parameters())[0].clone()\r\n",
    "        \r\n",
    "        # On met le gradient a 0\r\n",
    "        optimizer.zero_grad()#summa_parallel.zero_grad()        \r\n",
    " \r\n",
    "        # On passe la donnee au model et on recupere la loss et le logits (sortie avant fonction d'activation)\r\n",
    "        topvec=camem2(input_id,mask)\r\n",
    "        topvec=topvec.last_hidden_state.to(device)\r\n",
    "        #topvec=topvec.mul(mask_cls.unsqueeze(2)).to(device)\r\n",
    "        \r\n",
    "        sortie=model(topvec)\r\n",
    "        \r\n",
    "        #On calcule et garde le score pour information, mais le détache pour éviter de faire exploser la mémoire\r\n",
    "        f1_score+=score(sortie,output).detach().item()\r\n",
    "        prec_score+=score.precision(sortie,output).detach().item()\r\n",
    "\r\n",
    "        #output2=make_output_topk(output,k=1).long().to(device)\r\n",
    "        loss_train=loss(sortie,output).detach().item() # on commente detach sur la loss par rapport à laquelle on veut optimiser\r\n",
    "        loss_train_2=loss_2(sortie,output).detach().item()\r\n",
    "        loss_train_3=loss_3(sortie,output)#.detach().item()\r\n",
    "        \r\n",
    "        # Backpropagtion\r\n",
    "        loss_train_3.backward()\r\n",
    "        # On actualise les paramètres grace a l'optimizer\r\n",
    "        optimizer.step()\r\n",
    "        \r\n",
    "        # Checks if the weights did update, if not, informs at which step\r\n",
    "        param2=list(model.parameters())[0].clone()\r\n",
    "        check=bool(1-torch.equal(param1.data,param2.data))\r\n",
    "        if check==False:\r\n",
    "            print(\"The weights did not update at batch\",step,\"epoch\",epoch)        \r\n",
    "        \r\n",
    "        # Keep all the predictions\r\n",
    "        #pred.append(sortie.detach())\r\n",
    "\r\n",
    "        # .item() donne la valeur numerique de la loss\r\n",
    "        total_train_loss += loss_train#.detach().item() \r\n",
    "        total_train_loss_2 += loss_train_2#.detach().item() \r\n",
    "        total_train_loss_3 += loss_train_3.detach().item() \r\n",
    "\r\n",
    "    # On calcule les statistiques et les pertes moyennes sur toute l'epoque\r\n",
    "    f1_stat=f1_score/len(data)\r\n",
    "    prec_stat=prec_score/len(data)\r\n",
    "    avg_train_loss = total_train_loss / len(data)   \r\n",
    "    avg_train_loss_2 = total_train_loss_2 / len(data)   \r\n",
    "    avg_train_loss_3 = total_train_loss_3 / len(data)   \r\n",
    "\r\n",
    "    print(\"\\nAverage training loss MSE: {0:.4f}\".format(avg_train_loss),\r\n",
    "          \"\\nAverage training loss L1: {0:.4f}\".format(avg_train_loss_2),\r\n",
    "          \"\\nAverage training loss sum: {0:.4f}\".format(avg_train_loss_3),\r\n",
    "          \"\\nAverage f1 score: {0:.4f}\".format(f1_stat),\r\n",
    "          \"\\nAverage precision score: {0:.4f}\".format(prec_stat))  \r\n",
    "     \r\n",
    "    # Enregistrement des stats de l'epoque\r\n",
    "    training_stats.append(\r\n",
    "        {'epoch': epoch + 1,\r\n",
    "        'Training Loss MSE': avg_train_loss,\r\n",
    "        'Training Loss L1': avg_train_loss_2,\r\n",
    "        'Training Loss sum': avg_train_loss_3,\r\n",
    "        'Training f1 score': f1_stat,\r\n",
    "        'Training precision score':prec_stat})\r\n",
    "\r\n",
    "end=time.time()\r\n",
    "print(\"L'entraînement a duré :\",round((end-start)/60,2),\"minutes.\")\r\n",
    "\r\n",
    "pickle.dump(training_stats,open('training_stats_'+str(model).split('(')[0],'wb'))\r\n",
    "torch.save(model.state_dict(), str(model).split('(')[0]+\".pt\")\r\n",
    "torch.save(optimizer.state_dict(), str(model).split('(')[0]+'_'+str(optimizer).split(' (')[0]+\".pt\")\r\n",
    "print(\"Model saved!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/2095 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Entraînement du modèle : Multi_Linear_Classifier\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 32%|███▏      | 661/2095 [1:45:54<3:44:25,  9.39s/it]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "training_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "MSE=[]\r\n",
    "L1=[]\r\n",
    "S=[]\r\n",
    "F1=[]\r\n",
    "precision=[]\r\n",
    "for i in range(5):\r\n",
    "    MSE.append(training_stats[i]['Training Loss MSE'])\r\n",
    "    L1.append(training_stats[i]['Training Loss L1'])\r\n",
    "    S.append(training_stats[i]['Training Loss sum'])\r\n",
    "    F1.append(training_stats[i]['Training f1 score'])\r\n",
    "    precision.append(training_stats[i]['Training precision score'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "figue,hache=plt.subplots(2,figsize=(18,12))\r\n",
    "\r\n",
    "a,=hache[0].plot([i for i in range(5)],MSE,color='blue',label='MSE')\r\n",
    "#hache=hache.twinx()\r\n",
    "b,=hache[0].plot([i for i in range(5)],L1,color='red',label='L1')\r\n",
    "hache3=hache[0].twinx()\r\n",
    "c,=hache3.plot([i for i in range(5)],S,color='green',label='sum')\r\n",
    "p=[a,b,c]\r\n",
    "hache[0].legend(p,[p_.get_label() for p_ in p])\r\n",
    "\r\n",
    "a,=hache[1].plot([i for i in range(5)],F1,color='blue',label='MSE')\r\n",
    "#hache=hache.twinx()\r\n",
    "b,=hache[1].plot([i for i in range(5)],precision,color='red',label='L1')\r\n",
    "p=[a,b]\r\n",
    "hache[1].legend(p,[p_.get_label() for p_ in p])\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f349ccbed60>"
      ]
     },
     "metadata": {},
     "execution_count": 49
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1296x864 with 3 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparaison durée "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "for step, batch in enumerate(data):\r\n",
    "    if step==0:\r\n",
    "        start1=time.time()\r\n",
    "        input_id = batch[0].to(device)\r\n",
    "        mask = batch[1].to(device)\r\n",
    "        clss = batch[2].float().to(device)\r\n",
    "        mask_cls=batch[3].to(device)\r\n",
    "        output=batch[4].float().to(device)\r\n",
    "        end1=time.time()\r\n",
    "        print(end1-start1)\r\n",
    "    elif step==1:\r\n",
    "        start2=time.time()\r\n",
    "        input_id = batch[0]#.to(device)\r\n",
    "        mask = batch[1]#.to(device)\r\n",
    "        clss = batch[2].float()#.to(device)\r\n",
    "        mask_cls=batch[3]#.to(device)\r\n",
    "        output=batch[4].float()#.to(device)\r\n",
    "        end2=time.time()\r\n",
    "        print(end2-start2)\r\n",
    "    else:\r\n",
    "        break\r\n",
    "print((end1-start1)/(end2-start2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0012509822845458984\n",
      "0.00018358230590820312\n",
      "6.814285714285714\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "model=convnet\r\n",
    "optimizer=convnet_optimizer\r\n",
    "camem2.to('cpu')\r\n",
    "model.to(device)\r\n",
    "total_train_loss = 0\r\n",
    "total_train_loss_2 = 0\r\n",
    "total_train_loss_3 = 0\r\n",
    "f1_score=0\r\n",
    "prec_score=0\r\n",
    "start_total=time.time()\r\n",
    "for step, batch in enumerate(data):\r\n",
    "        if step==0:\r\n",
    "            # On recupere les donnees du batch\r\n",
    "            start=time.time()\r\n",
    "            input_id = batch[0]#.to(device)\r\n",
    "            mask = batch[1]#.to(device)\r\n",
    "            clss = batch[2].float().to(device)\r\n",
    "            mask_cls=batch[3]#.to(device)\r\n",
    "            output=batch[4].float().to(device)\r\n",
    "            end=time.time()\r\n",
    "            print(end-start)\r\n",
    "            param1=list(model.parameters())[0].clone()\r\n",
    "\r\n",
    "            # On met le gradient a 0\r\n",
    "            optimizer.zero_grad()#summa_parallel.zero_grad()        \r\n",
    "\r\n",
    "            # On passe la donnee au model et on recupere la loss et le logits (sortie avant fonction d'activation)\r\n",
    "            start=time.time()\r\n",
    "            topvec=camem2(input_id,mask)\r\n",
    "            topvec=topvec.last_hidden_state.to(device)\r\n",
    "            end=time.time()\r\n",
    "            print(end-start)\r\n",
    "            #topvec=topvec.mul(mask_cls.unsqueeze(2)).to(device)\r\n",
    "            start=time.time()\r\n",
    "            sortie=model(topvec)\r\n",
    "            end=time.time()\r\n",
    "            print(end-start)\r\n",
    "            \r\n",
    "            #On calcule et garde le score pour information, mais le détache pour éviter de faire exploser la mémoire\r\n",
    "            f1_score+=score(sortie,output).detach().item()\r\n",
    "            prec_score+=score.precision(sortie,output).detach().item()\r\n",
    "\r\n",
    "            #output2=make_output_topk(output,k=1).long().to(device)\r\n",
    "            loss_train=loss(sortie,output)#.detach() # on commente detach sur la loss par rapport à laquelle on veut optimiser\r\n",
    "            loss_train_2=loss_2(sortie,output).detach().item()\r\n",
    "            loss_train_3=loss_3(sortie,output).detach().item()\r\n",
    "\r\n",
    "            # Backpropagtion\r\n",
    "            start=time.time()\r\n",
    "            loss_train.backward()\r\n",
    "            # On actualise les paramètres grace a l'optimizer\r\n",
    "            optimizer.step()\r\n",
    "            end=time.time()\r\n",
    "            print(end-start)\r\n",
    "end_total=time.time()\r\n",
    "print(end_total-start_total)\r\n",
    "  "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0004534721374511719\n",
      "16.358054876327515\n",
      "0.004161357879638672\n",
      "43.16815209388733\n",
      "62.308534383773804\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "camem2.to('cpu')\r\n",
    "start=time.time()\r\n",
    "topvec=camem2(input_id,mask)\r\n",
    "end=time.time()\r\n",
    "print(end-start)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19.60832190513611\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.to(device)\r\n",
    "start=time.time()\r\n",
    "model.to('cpu')\r\n",
    "torch.cuda.empty_cache()\r\n",
    "camem2.to(device)\r\n",
    "camem2(input_id.to(device),mask.to(device))\r\n",
    "camem2.to('cpu')\r\n",
    "torch.cuda.empty_cache()\r\n",
    "model.to(device)\r\n",
    "end=time.time()\r\n",
    "print(end-start)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "t = torch.cuda.get_device_properties(0).total_memory\r\n",
    "r = torch.cuda.memory_reserved(0) \r\n",
    "a = torch.cuda.memory_allocated(0)\r\n",
    "f = r-a  # free inside reserved\r\n",
    "f/1024/1024/1024\r\n",
    "print(a/1024/1024)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "30.02001953125\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import print_function  # for Python2\r\n",
    "import sys\r\n",
    "\r\n",
    "local_vars = list(locals().items())\r\n",
    "for var, obj in local_vars:\r\n",
    "    print(var, sys.getsizeof(obj))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}