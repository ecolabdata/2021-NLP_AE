{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install gensim==3.8.3\r\n",
    "!pip install unidecode\r\n",
    "!pip install torch\r\n",
    "!pip install sentencepiece\r\n",
    "!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import time\r\n",
    "import pickle\r\n",
    "from pathlib import Path\r\n",
    "import gensim\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn\r\n",
    "import re\r\n",
    "from unidecode import unidecode\r\n",
    "import functools\r\n",
    "import operator\r\n",
    "import psutil\r\n",
    "from joblib import Parallel,delayed\r\n",
    "from functools import partial\r\n",
    "from time import time\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from tqdm import tqdm\r\n",
    "import os\r\n",
    "os.chdir(\"C:\\\\Users\\\\theo.roudil-valentin\\\\Documents\\\\Resume\\\\MLSUM\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "base=pickle.load(open('MLSUM_fr_val.pickle','rb'))\r\n",
    "pd.DataFrame(base.text.values[:10]).to_csv('MLSUM_fr_val.csv',sep=';')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from fats import Make_Extractive,Word_Cleaning\r\n",
    "W2V=None\r\n",
    "print(\"CPU dispo :\",psutil.cpu_count())\r\n",
    "cpu_max=24"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU dispo : 56\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fichiers=[i for i in os.listdir() if (i[-6:]=='pickle') and (i[:5]=='MLSUM')]\r\n",
    "fichiers_val=[i for i in fichiers if 'test' in i]\r\n",
    "\r\n",
    "for f in fichiers_val:\r\n",
    "    print(f)\r\n",
    "    base=pickle.load(open(f,'rb'))\r\n",
    "    name=f.split('.')[0].split('fr')[-1][1:]\r\n",
    "\r\n",
    "    print('Début du nettoyage du fichier',name,':')\r\n",
    "    cleaning_time=time()\r\n",
    "    WC=Word_Cleaning(n_jobs=cpu_max,sentence=True,threshold=True,seuil=2,lemma=False,seuil_carac=3)\r\n",
    "\r\n",
    "    summary=base.summary.values\r\n",
    "    summary=WC.make_summary(summary)\r\n",
    "    pickle.dump(summary,open('summary_clean_'+name+'.pickle','wb'))\r\n",
    "\r\n",
    "    text=base.text.values\r\n",
    "    text=WC.make_documents(text)\r\n",
    "    cleaning_end=time()\r\n",
    "    pickle.dump(text,open('text_clean_'+name+'.pickle','wb'))\r\n",
    "    print(\"Durée du nettoyage :\",round((cleaning_end-cleaning_time)/60,2),\"minutes.\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "summaries=[i for i in os.listdir() if 'summary' in i]\r\n",
    "texts=[i for i in os.listdir() if 'text' in i]\r\n",
    "\r\n",
    "text=pickle.load(open(texts[1],'rb'))\r\n",
    "summary=pickle.load(open(summaries[1],'rb'))\r\n",
    "longueur=[len(i) for i in sentence]\r\n",
    "\r\n",
    "assert len(text)==len(summary)\r\n",
    "\r\n",
    "dim=100\r\n",
    "fenetre=20\r\n",
    "minimum=1\r\n",
    "epo=5\r\n",
    "\r\n",
    "ME=Make_Extractive(cpu=cpu_max)\r\n",
    "\r\n",
    "sentence=ME.make_w2v_sentences(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "#Pour 15800, le W2V a pris 3,3 minutes \r\n",
    "if W2V==None:\r\n",
    "    import gensim\r\n",
    "    try:\r\n",
    "        W2V=gensim.models.Word2Vec(size=dim,window=fenetre,min_count=minimum)\r\n",
    "    except:\r\n",
    "        W2V=gensim.models.Word2Vec(vector_size=dim,window=fenetre,min_count=minimum)\r\n",
    "    W2V.build_vocab(sentence)\r\n",
    "    print(\"Démarrage de l'entraînement du modèle Word2Vec.\")\r\n",
    "    start=time()\r\n",
    "    W2V.train(sentence,total_examples=W2V.corpus_count,epochs=epo)\r\n",
    "    end=time()\r\n",
    "    print(\"Le modèle W2V est désormais entraîné et cela a pris :\",round((end-start)/60,2),\"minutes.\")\r\n",
    "\r\n",
    "#Pour 15800, le dico vocab a pris 0 minutes \r\n",
    "start=time()\r\n",
    "try:\r\n",
    "    vocab=list(W2V.wv.vocab.keys())\r\n",
    "except:\r\n",
    "    vocab=list(set(W2V.wv.key_to_index))\r\n",
    "end=time()\r\n",
    "print(\"La création du dico vocab a pris:\",round((end-start)/60,2),\"minutes.\")\r\n",
    "\r\n",
    "#Pour 15800, le découpage a pris 0 minutes \r\n",
    "start=time()\r\n",
    "text=Parallel(n_jobs=cpu_max)(delayed(ME.make_splitting)(s) for s in text)\r\n",
    "#text=[[i.split() for i in s] for s in docs]\r\n",
    "\r\n",
    "summary=ME.make_splitting(summary)\r\n",
    "\r\n",
    "#summary=[[i for i in s.split() if i in vocab] for s in summary]\r\n",
    "end=time()\r\n",
    "print(\"Le découpage des phrases a pris:\",round((end-start)/60,2),\"minutes.\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "La création du dico vocab a pris: 0.0 minutes.\n",
      "Le découpage des phrases a pris: 0.09 minutes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "sent=text[0]\r\n",
    "s=sent[0]\r\n",
    "torch.stack(\r\n",
    "             [cosim(torch.as_tensor(W2V.wv[i]),torch.as_tensor(W2V.wv[summary[text.index(sent)]]))\r\n",
    "             for i in s]).mean()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(0.0067)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "gensim.__version__>'4.0.0'"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cosim=torch.nn.CosineSimilarity(-1)\r\n",
    "\r\n",
    "score=[]\r\n",
    "erreur=[]\r\n",
    "for sent in tqdm(text):\r\n",
    "    score_=[]\r\n",
    "    for s in sent:\r\n",
    "        try:\r\n",
    "            score_.append(torch.stack(\r\n",
    "             [cosim(torch.as_tensor(W2V[i]),torch.as_tensor(W2V[summary[text.index(sent)]]))\r\n",
    "             for i in s]).mean())\r\n",
    "        except:\r\n",
    "            erreur.append([text.index(sent),sent.index(s)])\r\n",
    "            print(\"Attention, l'élément\",erreur[-1],\"n'a pas pu être encodé.\")\r\n",
    "            continue\r\n",
    "    try:\r\n",
    "        score.append(torch.stack(score_))\r\n",
    "    except:\r\n",
    "        score.append(torch.Tensor())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from fats import Make_Extractive\r\n",
    "\r\n",
    "summaries=[i for i in os.listdir() if ('summary_word_3' in i) and ('train' not in i)]\r\n",
    "texts=[i for i in os.listdir() if ('text_word_3' in i) and ('train' not in i)]\r\n",
    "W2V=pickle.load(open('W2V_train.pickle','rb'))\r\n",
    "\r\n",
    "cpu_max=30\r\n",
    "n=10\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "for summary,text in zip(summaries,texts):\r\n",
    "        name='train_'+summary.split('.')[0].split('_')[-1]\r\n",
    "        print(name)\r\n",
    "        text=pickle.load(open(text,'rb'))\r\n",
    "        summary=pickle.load(open(summary,'rb'))\r\n",
    "        score_final=[]\r\n",
    "        erreur_f=[]\r\n",
    "        for l in range(n):\r\n",
    "            if l<3:\r\n",
    "                l_1=int(len(text)*(l)/n)\r\n",
    "                l_2=int(len(text)*(l+1)/n)\r\n",
    "                print(l_1,l_2)\r\n",
    "                text_=text[l_1:l_2]\r\n",
    "                summary_=summary[l_1:l_2]\r\n",
    "                print(\"Début de la création de l'output :\")\r\n",
    "                output_time=time()\r\n",
    "                ME=Make_Extractive(cpu=cpu_max,fenetre=20,minimum=1,d=100,epochs=25)\r\n",
    "                score,text_2,summary_2,erreur=ME.make_output(text_,summary_,W2V=W2V)\r\n",
    "                output_end=time()\r\n",
    "                print(\"Durée de la création d'output :\",round((output_end-output_time)/60,2),\"minutes.\") #42 minutes pour 15,8K lignes\r\n",
    "                print(\"Nombre d'erreurs pendant l'encodage du test :\",round(len(erreur)/len(text_)*100,2),\"%\")\r\n",
    "                score_final+=score\r\n",
    "                erreur_f+=erreur\r\n",
    "                pickle.dump(score,open('score_'+name+'_'+str(l+1)+'.pickle','wb'))\r\n",
    "            else:\r\n",
    "                break\r\n",
    "        score=pickle.load(open('score_train_3.pickle','rb'))\r\n",
    "        erreur=pickle.load(open('erreur_word_train_3.pickle','rb'))\r\n",
    "        score_final=score+score_final\r\n",
    "        pickle.dump(score_final,open('score_'+name+'.pickle','wb'))\r\n",
    "        erreur_f=erreur_f+erreur\r\n",
    "        pickle.dump(erreur_f,open('erreur_word_'+name+'.pickle','wb'))\r\n",
    "        for l in range(n):\r\n",
    "            os.remove('score_'+name+'_'+str(l+1)+'.pickle')\r\n",
    "        #print(score_final)\r\n",
    "        #pickle.dump(W2V,open('W2V_'+name+'.pickle','wb'))\r\n",
    "        #pickle.dump(text_2,open('text_word_'+name+'.pickle','wb'))\r\n",
    "        #pickle.dump(summary_2,open('summary_word_'+name+'.pickle','wb'))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/9822 [00:00<06:18, 25.97it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 9822\n",
      "Début de la création de l'output :\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9822/9822 [12:11<00:00, 13.42it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Durée de la création d'output : 12.2 minutes.\n",
      "Nombre d'erreurs pendant l'encodage du test : 5.06 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/9823 [00:00<06:04, 26.97it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9822 19645\n",
      "Début de la création de l'output :\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 9823/9823 [12:56<00:00, 12.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Durée de la création d'output : 12.94 minutes.\n",
      "Nombre d'erreurs pendant l'encodage du test : 4.72 %\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 3/9822 [00:00<05:29, 29.76it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "19645 29467\n",
      "Début de la création de l'output :\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 62%|██████▏   | 6107/9822 [07:06<06:30,  9.52it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "len(score_final)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29467"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "score=pickle.load(open('score_train_3.pickle','rb'))\r\n",
    "print(len(score))\r\n",
    "erreur=pickle.load(open('erreur_word_train_3.pickle','rb'))\r\n",
    "print(len(erreur))\r\n",
    "score_final=score+score_final\r\n",
    "print(len(score_final))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68758\n",
      "3477\n",
      "98225\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "pickle.dump(score_final,open('score_'+name+'.pickle','wb'))\r\n",
    "erreur_f=erreur_f+erreur\r\n",
    "print(len(erreur_f))\r\n",
    "pickle.dump(erreur_f,open('erreur_word_'+name+'.pickle','wb'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4827\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pickle.dump(score_final,open('score_train_1_1.pickle','wb'))\r\n",
    "pickle.dump(erreur_f,open('erreur_word_train_1_1.pickle','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "len(score)+29467,len(text)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(98225, 98225)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "#text=pickle.load(open('text_word_3.pickle','rb'))\r\n",
    "\r\n",
    "x=0\r\n",
    "for t in text:\r\n",
    "    x+=len(t)\r\n",
    "print(\"Nombre de données :\",x)\r\n",
    "#erreur=pickle.load(open('erreur_word_train_3.pickle','rb'))\r\n",
    "print(\"Nombre d'erreurs pendant l'encodage du text :\",round(len(erreur)/x*100,2),\"%\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Nombre de données : 2242804\n",
      "Nombre d'erreurs pendant l'encodage du text : 0.16 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "len(summary[0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "text=pickle.load(open('text_clean_train_3.pickle','rb'))\r\n",
    "score=pickle.load(open('score_train_3.pickle','rb'))\r\n",
    "print(len(text),len(score))\r\n",
    "\r\n",
    "relou=[i for i in range(len(score)) if len(text[i])!=len(score[i])]\r\n",
    "print(len(relou))\r\n",
    "\r\n",
    "def remove_empty(text):\r\n",
    "    while '' in text:\r\n",
    "          text.remove('')\r\n",
    "    return text\r\n",
    "\r\n",
    "text_ne=Parallel(n_jobs=cpu_max)(delayed(remove_empty)(t) for t in text)\r\n",
    "print(len(text_ne),len(score))\r\n",
    "relou=[i for i in range(len(score)) if len(text_ne[i])!=len(score[i])]\r\n",
    "print(len(relou))\r\n",
    "\r\n",
    "index=[i for i in range(len(text_ne)) if i not in relou]\r\n",
    "\r\n",
    "text_ne=[text_ne[i] for i in index]\r\n",
    "score_ne=[score[i] for i in index]\r\n",
    "print(len(text_ne),len(score_ne))\r\n",
    "\r\n",
    "relou=[i for i in range(len(text_ne)) if len(text_ne[i])!=len(score_ne[i])]\r\n",
    "print(len(relou))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "98225 98225\n",
      "95722\n",
      "98225 98225\n",
      "95709\n",
      "2516 2516\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "W2V=pickle.load(open('W2V_train.pickle','rb'))\r\n",
    "\r\n",
    "erreur_text={}\r\n",
    "score_relou=[]\r\n",
    "for k in relou:\r\n",
    "    nul=[]\r\n",
    "    for i in range(len(text[k])):\r\n",
    "        try:\r\n",
    "            W2V.wv[text[k][i].split()]\r\n",
    "        except:\r\n",
    "            #print(k,i)\r\n",
    "            nul.append(i)\r\n",
    "    erreur_text[k]=nul\r\n",
    "    if len(erreur_text[k])>0:\r\n",
    "        for e in list(reversed(erreur_text[1915])):\r\n",
    "            score_=torch.cat([score[k][:e],torch.Tensor([0]),score[k][e:]])\r\n",
    "        score_relou.append(score_)\r\n",
    "\r\n",
    "erreur_text"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#texts=[i for i in os.listdir() if 'text_clean' in i]\r\n",
    "#scores=[i for i in os.listdir() if 'score' in i]\r\n",
    "\r\n",
    "#for text,score in zip(texts,scores):\r\n",
    "#name=text.split('.')[0].split('_')[-1]\r\n",
    "\r\n",
    "#text=pickle.load(open(text,'rb'))\r\n",
    "#score=pickle.load(open(score,'rb'))\r\n",
    "\r\n",
    "print(\"Début de la création de l'encoding\")\r\n",
    "encoding_time=time()\r\n",
    "ME=Make_Extractive(cpu_max)\r\n",
    "dico=ME.make_encoding(text_ne,score_ne,voc_size=12000,split=1)\r\n",
    "encoding_end=time()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Durée de la création d'output :\",round((encoding_end-encoding_time)/60,2),\"minutes.\")\r\n",
    "\r\n",
    "pickle.dump(dico,open('dico_train_3.pickle','wb'))\r\n",
    "print(\"Les données du val ont été sauvegardées !\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from transformers import CamembertTokenizer\r\n",
    "tokenizer=CamembertTokenizer('essai.model')\r\n",
    "ME=Make_Extractive(cpu=cpu_max)\r\n",
    "doc_encod=partial(ME.document_encoding,tokenizer=tokenizer,dim=512)   \r\n",
    "output=[]#Parallel(n_jobs=cpu_max)(delayed(\r\n",
    "erreur=[]\r\n",
    "for t,s in tqdm(zip(text_ne,score_ne)):\r\n",
    "    try:\r\n",
    "        output.append(doc_encod(t,s))\r\n",
    "    except:\r\n",
    "        erreur.append(text_ne.index(t))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "15128it [02:13, 113.61it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "erreur"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[9102, 9151]"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "len(score_ne[9102]),len(text_ne[9102])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print('ouais')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ouais\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "interpreter": {
   "hash": "e34048b0732ca5da544928c261c6b0ec51b7f57de61b26cf2eebb756a9ee889a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}