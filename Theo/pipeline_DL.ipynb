{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4728576-1a31-4d1b-aca5-2282ab3a0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim==3.8.3\n",
    "!pip install unidecode\n",
    "!pip install torch\n",
    "!pip install sentencepiece\n",
    "!pip install transformers\n",
    "!pip install bs4\n",
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd4b62f-fb5f-40db-a65c-35dc69ca1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from joblib.parallel import cpu_count\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import functools\n",
    "import operator\n",
    "from joblib import Parallel,delayed\n",
    "from functools import partial\n",
    "import sentencepiece as spm \n",
    "import psutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "from transformers.utils.dummy_pt_objects import CamembertModel\n",
    "from transformers import CamembertTokenizer\n",
    "from unidecode import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "import gensim\n",
    "import fats\n",
    "from transformers import CamembertModel\n",
    "camem2=CamembertModel.from_pretrained(\"camembert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3def23a4-130b-4198-8fd5-5cef55b821fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichiers=[i for i in os.listdir() if (i[-6:]=='pickle') and (i[:5]=='MLSUM')]\n",
    "fichiers_val=[i for i in fichiers if 'test' in i]\n",
    "test=pickle.load(open('MLSUM_fr_test.pickle','rb'))\n",
    "texte=[test.text[:10].values.tolist()[i].split('.') for i in range(10)]\n",
    "tok='MLSUM_tokenizer.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cb5cf9-9e15-4754-bdad-bfe05db15532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/root/work/fats.py:1410: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  vec=[(dico['mask_cls'][i]==torch.tensor(1)).nonzero() for i in range(len(dico['mask_cls']))]\n"
     ]
    }
   ],
   "source": [
    "r=fats.make_DL_resume(texte,cpu=2,choose_model='SMHA',get_score_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693cca84-ab6f-4de8-9e17-80f1dfa775b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' CARL RECINE / REUTERS Liverpool au sommet de l’Europe… et de l’ennui',\n",
       "  ' Les Reds, pour ne pas se découvrir, ont allongé le jeu et outre l’intenable Salah (21e, 22e, 39e), seuls les latéraux Trent Alexander-Arnold, d’une frappe trop croisée (17e), et Andy Robertson, d’un tir claqué par Lloris (38e), ont instillé quelques frissons dans la torpeur ambiante',\n",
       "  ' En 2018, les bourdes du gardien Loris Karius avaient plombé Liverpool'],\n",
       " [' C’est au contraire comme un vagabond ami de la Terre, arpenteur inventif, ouvert aux fécondités du hasard',\n",
       "  ' Michel Serres aura sans doute rendu à la philosophie française son sens de la rencontre, de l’imprévu, du jeu',\n",
       "  ' Une affaire de style plutôt, et de tempérament'],\n",
       " [' Or Michel Serres fut un grand voyageur – ce qui lui permit d’être, aussi, un prodigieux conteur d’histoires',\n",
       "  ' Michel Serres est décédé samedi 1er juin, à l’âge de 88 ans',\n",
       "  ' A l’intérieur de celui-ci, le plus petit opuscule, le moindre sous-système reproduit la structure de l’ensemble'],\n",
       " [' Dominé physiquement et fébrile en première période, le LOU a fini par étouffer Montpellier en barrages du Top 14 (21-16), samedi 1er juin dans la fournaise de Gerland et au bout du suspense',\n",
       "  ' Les Lyonnais se qualifient pour les demi-finales pour la seconde année consécutive',\n",
       "  ' Le premier s’est ainsi fait contrer par Aaron Cruden, dont l’essai a placé Montpellier en tête (4), alors que le second a perdu un ballon facile qui a permis à Benoît Paillaugue de creuser l’écart (11, 10-0)'],\n",
       " [' Plusieurs élus locaux berlinois, des membres du Bundestag, ainsi que l’ambassadeur des Etats-Unis en Allemagne, Richard Grenell, et le commissaire du gouvernement chargé de l’antisémitisme, Felix Klein, ont participé à ce rassemblement, au-dessus duquel flottaient des drapeaux israéliens, dans le centre de la capitale',\n",
       "  ' Klein lors du rassemblement',\n",
       "  ' Un Israélien portant la kippa avait été frappé à coups de ceinture par un Syrien dans le quartier huppé de Prenzlauer Berg'],\n",
       " [' Sa postérité sera établie en 1972 grâce à son insertion dans Nuggets : Original Artyfacts from the First Psychedelic Era, 1965 – 1968, un double album compilé par le critique (et futur guitariste de Patti Smith) Lenny Kaye, devenue la bible des amateurs de garage et d’acid rock',\n",
       "  ' L’impression que les musiciens évoluent dans une caverne The 13th Floor Elevators – le 13e étage est souvent omis, par superstition, dans les ascenseurs aux Etats-Unis – reste associé à You’re Gonna Miss Me, une composition d’Erickson publiée en 45-tours en 1966, peu après la formation du quintette à Austin',\n",
       "  ' Les « ascenseurs », qui sont parmi les premiers à faire usage du mot psychédélisme, en profitent pour livrer leur premier album, The Psychedelic Sounds of the 13th Floor Elevators, canonique d’une esthétique usant de la pédale fuzz pour la saturation des guitares et d’une réverbération qui donne l’impression que les musiciens évoluent non pas dans un garage, mais dans une caverne'],\n",
       " [' RYAD KRAMDI / AFP Plusieurs milliers de personnes ont assisté samedi 1er juin à Alger à l’enterrement de Kamel Eddine Fekhar, un militant des droits humains mort en détention',\n",
       "  ' Il faisait partie des militants arrêtés après des violences communautaires dont la région du M’zab (dont Ghardaïa est la principale ville) a été le théâtre en 2015 entre Mozabites, des Berbères de rite ibadite, un courant minoritaire de l’islam, et Chaâmbas, des Arabes de rite malékite',\n",
       "  ' Kamel Eddine Fekhar avait déjà purgé une peine de deux ans de prison notamment pour « atteinte à la sûreté de l’Etat » et « trouble à l’ordre public » et avait été libéré en juillet 2017'],\n",
       " [' DENIS GLIKSMAN / INRAP Ouvrez votre portefeuille',\n",
       "  ' Les grandes heures des ducs de Bourgogne se sont achevées avec la mort de Charles le Téméraire en 1477 mais « sous leur impulsion, la ville a connu des modifications importantes, souligne Stéphane Alix, responsable scientifique de l’équipe qui a réalisé la découverte',\n",
       "  ' » Concrétion Lors de sa mise au jour, en janvier, la petite boîte métallique contenant les monnaies ainsi qu’un petit pendentif n’était plus que morceaux épars et corrodés'],\n",
       " [' Cela dit, avec l’ancien bateau on cherchait encore… », sourit-il',\n",
       "  ' Je me dis qu’à quatrième étape, j’arriverai peut-être à le maîtriser',\n",
       "  ' On cherche à quoi correspondent les ficelles à bord'],\n",
       " [' Il y retourne et trouve comme seule explication la même que Samuel Beckett, quand on lui avait demandé un jour pourquoi il écrivait : « Bon qu’à ça',\n",
       "  ' Mais surtout naviguer sur ce type de bateau, c’est avoir le goût des intérieurs bien astiqués – celui d’un Figaro a toujours été grand comme un coin cuisine – et avoir aussi dans son arbre un aïeul écossais, car le goût de la victoire à l’économie est capital : le classement s’effectue au temps, le vainqueur est donc celui ou celle qui met le moins de temps au cumul de toutes les étapes',\n",
       "  ' Eh bien non : ils sont de retour']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205c68c-540c-4090-9ee9-4286a2197425",
   "metadata": {},
   "source": [
    "## On prend en exemple un ensemble d'articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16fae6c-b5b1-4512-ba8e-0e3d2a9800c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 14, 15, 16]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=Parallel(n_jobs=1)(delayed(fats.make_text)(t) for t in texte)\n",
    "text[0][1]\n",
    "\n",
    "\n",
    "#dico=fats.Make_Extractive(5).make_encoding(text,voc_size=12000,split=1,tokenizer=tok,training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e410348a-a636-4d8b-8fa0-323b99c4a722",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[i for i in range(len(texte[0]))]\n",
    "for i in t1ouf:\n",
    "    a.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050647f3-2593-4c99-b5ca-9f0313a8f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[i for i in range(len(a))]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1dc57d02-05fd-49fb-afbb-c1d76c3869a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMHAL=fats.SMHA_Linear_classifier(torch.Size([512,768]),8,768)\n",
    "SMHAL.load_state_dict(torch.load('SMHA_Linear_classifier.pt',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9067220f-64df-4a4e-b8d2-870af5a57195",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMHAL.eval()\n",
    "y=SMHAL(camem2(torch.Tensor(dico['input']).long(),torch.Tensor(dico['mask']).long()).last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da74d99-5c9c-41f3-9b32-e93fc2937389",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.mul(dico['mask_cls'],y).topk(3)\n",
    "values=t[0]\n",
    "indice=t[1]\n",
    "vec=[(dico['mask_cls'][i]==torch.tensor(1)).nonzero() for i in range(len(dico['mask_cls']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9c17363-998b-4da9-9ab1-33b82b9f44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ve=[]\n",
    "V=[]\n",
    "I=[]\n",
    "ind=0\n",
    "for i in range(len(dico['trace'])):\n",
    "    Ve.append(vec[ind:ind+dico['trace'][i]])\n",
    "    V.append(values[ind:ind+dico['trace'][i]])\n",
    "    I.append(indice[ind:ind+dico['trace'][i]])\n",
    "    ind+=dico['trace'][i]\n",
    "V=[v.reshape(-1) for v in V]\n",
    "I=[v.reshape(-1) for v in I]\n",
    "I2=[torch.cat([I[k][i*3:(i+1)*3]+512*i for i in range(int(len(I[k])/3))]) for k in range(len(I))]\n",
    "Ve2=[torch.cat([Ve[k][i]+512*i for i in range(len(Ve[k]))]).squeeze(1) for k in range(len(Ve))]\n",
    "index=[torch.div(V[i],V[i].sum()).topk(k=3)[1] for i in range(len(V))]\n",
    "vrai_index=[I2[i][index[i]] for i in range(len(texte))]\n",
    "rindex=[torch.cat([(Ve2[k]==vrai_index[k][i]).nonzero().squeeze(1) for i in range(3)]) for k in range(len(Ve2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdefde98-b94c-499a-a98b-79a405bf7ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 1, 18, 15]),\n",
       " tensor([19, 20,  4]),\n",
       " tensor([ 2, 88, 17]),\n",
       " tensor([ 2,  3, 23]),\n",
       " tensor([ 3, 10, 16]),\n",
       " tensor([ 9,  4, 10]),\n",
       " tensor([ 1, 11, 10]),\n",
       " tensor([ 1,  8, 10]),\n",
       " tensor([12, 18, 11]),\n",
       " tensor([52, 18,  2])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de358d3b-4176-4f51-8a0f-071a1469245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(text)):\n",
    "    for i in rindex[k]:\n",
    "        try:\n",
    "            text[k][i]\n",
    "        except:\n",
    "            print(k,i)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cd2894cf-a898-4424-812b-f8fa5bd40d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['carl recine reuters liverpool sommet europe ennui',\n",
       "  'okepamzchv rmcsport rmc sport mais cinquieme but egyptien dans cette qui aurait enflammer rencontre contraire assomme tout monde',\n",
       "  'tout avait pourtant commence par coup froid des premiere action debordement sadio mane centre detourne epaule puis bras par sissoko penalty siffle apres seulement jeu plus rapide dans histoire des finales'],\n",
       " ['est contraire comme vagabond ami terre arpenteur inventif ouvert aux fecondites hasard',\n",
       "  'michel serres aura sans doute rendu philosophie francaise son sens rencontre imprevu jeu',\n",
       "  'une affaire style plutot temperament'],\n",
       " ['michel serres est decede samedi juin age ans', 'demission retour lycee'],\n",
       " ['domine physiquement febrile premiere periode lou fini par etouffer montpellier barrages top samedi juin dans fournaise gerland bout suspense',\n",
       "  'les lyonnais qualifient pour les demi finales pour seconde annee consecutive'],\n",
       " ['plusieurs elus locaux berlinois des membres bundestag ainsi que ambassadeur des etats unis allemagne richard grenell commissaire gouvernement charge antisemitisme felix klein ont participe rassemblement dessus duquel flottaient des drapeaux israeliens dans centre capitale',\n",
       "  'klein lors rassemblement',\n",
       "  'israelien portant kippa avait ete frappe coups ceinture par syrien dans quartier huppe prenzlauer berg'],\n",
       " ['posterite sera etablie grace son insertion dans nuggets original artyfacts from the first psychedelic era double album compile par critique futur guitariste patti smith lenny kaye devenue bible des amateurs garage acid rock',\n",
       "  'impression que les musiciens evoluent dans une caverne the floor elevators etage est souvent omis par superstition dans les ascenseurs aux etats unis reste associe you gonna miss une composition erickson publiee tours peu apres formation quintette austin',\n",
       "  'les ascenseurs qui sont parmi les premiers faire usage mot psychedelisme profitent pour livrer leur premier album the psychedelic sounds the floor elevators canonique une esthetique usant pedale fuzz pour saturation des guitares une reverberation qui donne impression que les musiciens evoluent non pas dans garage mais dans une caverne'],\n",
       " ['ryad kramdi afp plusieurs milliers personnes ont assiste samedi juin alger enterrement kamel eddine fekhar militant des droits humains mort detention',\n",
       "  'faisait partie des militants arretes apres des violences communautaires dont region zab dont ghardaia est principale ville ete theatre entre mozabites des berberes rite ibadite courant minoritaire islam chaambas des arabes rite malekite',\n",
       "  'kamel eddine fekhar avait deja purge une peine deux ans prison notamment pour atteinte surete etat trouble ordre public avait ete libere juillet'],\n",
       " ['denis gliksman inrap ouvrez votre portefeuille',\n",
       "  'les grandes heures des ducs bourgogne sont achevees avec mort charles temeraire mais sous leur impulsion ville connu des modifications importantes souligne stephane alix responsable scientifique equipe qui realise decouverte',\n",
       "  'concretion lors mise jour janvier petite boite metallique contenant les monnaies ainsi petit pendentif etait plus que morceaux epars corrodes'],\n",
       " ['cela dit avec ancien bateau cherchait encore sourit',\n",
       "  'dis quatrieme etape arriverai peut etre maitriser',\n",
       "  'cherche quoi correspondent les ficelles bord'],\n",
       " ['mais surtout naviguer sur type bateau est avoir gout des interieurs bien astiques celui figaro toujours ete grand comme coin cuisine avoir aussi dans son arbre aieul ecossais car gout victoire economie est capital classement effectue temps vainqueur est donc celui celle qui met moins temps cumul toutes les etapes',\n",
       "  'pour cet anniversaire cette course hauturiere sur des bateaux tous identiques annonce sans pareille']]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resu=[[text[i][k] for k in rindex[i]] for i in range(len(text))]\n",
    "resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d220f-a543-472e-b222-e592b2b52f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[torch.cat([(Ve2[k]==vrai_index[k][i]).nonzero().squeeze(1) for i in range(3)]) for k in range(len(Ve2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151eeaab-7a55-401f-8086-c2f6e9be948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Ve2==vrai_index).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92eb7c6-9d92-448f-a415-16f3768719d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=[(dico['mask_cls'][i]==torch.tensor(1)).nonzero() for i in range(len(dico['mask_cls']))]\n",
    "rindex=[torch.transpose((vec[i]==t[1][i]).nonzero(),0,1)[0] for i in range(len(t[1]))]\n",
    "rindex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45e744-8cd4-4ac1-bade-6ee852a0ab15",
   "metadata": {},
   "source": [
    "## Pour différents paragraphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37570b9d-3b7b-4111-a2c6-247041605aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fichiers=[i for i in os.listdir() if (i[-6:]=='pickle') and (i[:5]=='MLSUM')]\n",
    "fichiers_val=[i for i in fichiers if 'test' in i]\n",
    "test=pickle.load(open('MLSUM_fr_test.pickle','rb'))\n",
    "texte=[test.text[:10].values.tolist()[i].split('.') for i in range(10)] #Liste de liste de phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e5bd85c-c940-4f4b-a144-466642100ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DL_resume(texte,cpu,choose_model,k=3,camem=None,vs=12000,sp=1,tok='MLSUM_tokenizer.model',tr=False,get_score_only=False):\n",
    "    try :\n",
    "        assert choose_model in ['SMHA','Simple','Net','Multi']\n",
    "    except:\n",
    "        raise ValueError(\"Attention, le nom de votre modèle n'est pas correcte, il doit faire partie des noms suivants :\\nSMHA (pour Self Multi Head Attention),\\nSimple (pour Simple Linear Classifier),\\nNet (pour Convolutional Network),\\nMulti (pour Multi Linear)\")\n",
    "    \n",
    "    try:\n",
    "        assert np.sum([1 if choose_model in i else 0 for i in os.listdir()])>0\n",
    "    except:\n",
    "        raise ValueError(\"Attention, ce que vous avez entré pour la variable choose_model ne semble pas convenir. Vous ne possédez probablement pas le modèle dans votre dossier ou l'avez mal rebaptisé. Les noms corrects sont les suivants :\\nSMHA_Linear_classifier.pt,\\nSimple_Classifier.pt,\\nNet.pt,\\nMulti_Linear_Classifier.pt\")\n",
    "        \n",
    "    if camem==None:\n",
    "        from transformers import CamembertModel\n",
    "        camem=CamembertModel.from_pretrained(\"camembert-base\")\n",
    "        \n",
    "    Text=Parallel(n_jobs=cpu)(delayed(fats.make_text)(t) for t in texte)\n",
    "    text=[i[0] for i in Text]\n",
    "    empty=[i[1] for i in Text]\n",
    "    dico=fats.Make_Extractive(cpu).make_encoding(text,voc_size=vs,split=sp,tokenizer=tok,training=tr)\n",
    "    \n",
    "    if choose_model=='SMHA':\n",
    "        model=fats.SMHA_Linear_classifier(torch.Size([512,768]),8,768)\n",
    "        model.load_state_dict(torch.load('SMHA_Linear_classifier.pt',map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "    \n",
    "    elif choose_model=='Simple':\n",
    "        model=fats.Simple_Classifier(camem.config.hidden_size)\n",
    "        model.load_state_dict(torch.load('Simple_Classifier.pt',map_location=torch.device('cpu')))\n",
    "        model.eval()\n",
    "    \n",
    "    elif choose_model=='Net':\n",
    "        model=fats.Net(2**8,2**6,2,2,2,2)\n",
    "        model.load_state_dict(torch.load('Net.pt',map_location=torch.device('cpu')))\n",
    "        model.eval()    \n",
    "        \n",
    "    elif choose_model=='Multi':\n",
    "        model=fats.Multi_Linear_Classifier(camem.config.hidden_size)\n",
    "        model.load_state_dict(torch.load('Multi_Linear_Classifier.pt',map_location=torch.device('cpu')))\n",
    "        model.eval()    \n",
    "    \n",
    "    y=model(camem(torch.Tensor(dico['input']).long(),torch.Tensor(dico['mask']).long()).last_hidden_state)\n",
    "    t=torch.mul(dico['mask_cls'],y).topk(3)\n",
    "    vec=[(dico['mask_cls'][i]==torch.tensor(1)).nonzero() for i in range(len(dico['mask_cls']))]\n",
    "    values=t[0]\n",
    "    indice=t[1]\n",
    "    Ve=[]\n",
    "    Va=[]\n",
    "    I=[]\n",
    "    ind=0\n",
    "    for i in range(len(dico['trace'])):\n",
    "        Ve.append(vec[ind:ind+dico['trace'][i]])\n",
    "        Va.append(values[ind:ind+dico['trace'][i]])\n",
    "        I.append(indice[ind:ind+dico['trace'][i]])\n",
    "        ind+=dico['trace'][i]\n",
    "        \n",
    "    Va=[v.reshape(-1) for v in Va]\n",
    "    I=[v.reshape(-1) for v in I]\n",
    "    \n",
    "    I2=[torch.cat([I[k][i*3:(i+1)*3]+512*i for i in range(int(len(I[k])/3))]) for k in range(len(I))]\n",
    "    Ve2=[torch.cat([Ve[k][i]+512*i for i in range(len(Ve[k]))]).squeeze(1) for k in range(len(Ve))]\n",
    "\n",
    "    index=[torch.div(Va[i],Va[i].sum()).topk(k=3)[1] for i in range(len(Va))]\n",
    "    vrai_index=[I2[i][index[i]] for i in range(len(texte))]\n",
    "\n",
    "    rindex=[torch.cat([(Ve2[h]==vrai_index[h][i]).nonzero().squeeze(1) for i in range(k)]) for h in range(len(Ve2))]\n",
    "    \n",
    "    a=[i for i in range(len(texte[0]))]\n",
    "    for i in t1ouf:\n",
    "        a.remove(i)\n",
    "    \n",
    "    \n",
    "    if get_score_only:\n",
    "        return rindex,vrai_index,Ve2,I2\n",
    "    else:\n",
    "        resu=[[text[i][k] for k in rindex[i]] for i in range(len(text))]\n",
    "        return resu\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f78af50-4980-404d-97f2-05a9849a7f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'train_input_ids' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-924dfa79185f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_DL_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexte\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchoose_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Simple'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_score_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/fats.py\u001b[0m in \u001b[0;36mmake_DL_resume\u001b[0;34m(texte, cpu, choose_model, k, camem, vs, sp, tok, tr, get_score_only)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m     \u001b[0mText\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m     \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m     \u001b[0mempty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mText\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0mdico\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMake_Extractive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvoc_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/fats.py\u001b[0m in \u001b[0;36mmake_encoding\u001b[0;34m(self, text, output, tokenizer, voc_size, prefix, name, split, dim, training)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             dico_train={\n\u001b[0;32m--> 625\u001b[0;31m                \u001b[0;34m'input'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                \u001b[0;34m'mask'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                \u001b[0;34m'segs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_segs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'train_input_ids' referenced before assignment"
     ]
    }
   ],
   "source": [
    "r=fats.make_DL_resume(texte,cpu=2,choose_model='Simple',get_score_only=True)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba3b302-21c8-4893-a62c-6596606aa262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 tensor(18)\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(text)):\n",
    "    for i in r[k]:\n",
    "        try:\n",
    "            text[k][i]\n",
    "        except:\n",
    "            print(k,i)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def68fe3-1029-4e23-987d-9724cc01d7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0],\n",
       "        [1, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ME=fats.Make_Extractive(cpu=5).make_encoding(text=text,tokenizer=tok,training=False)\n",
    "(torch.Tensor(ME['input'])==torch.tensor(5)).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87d31e-2f74-40ec-b078-5a300d6f6ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
