{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a470b12-e901-4904-ac3b-810372a88ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import operator\n",
    "import psutil\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from transformers import CamembertTokenizer,CamembertModel\n",
    "from joblib import Parallel,delayed\n",
    "#import os\n",
    "#os.chdir(\"home/jovyan/work\")\n",
    "tok=CamembertTokenizer('MLSUM_tokenizer.model')\n",
    "camem=CamembertModel.from_pretrained(\"camembert-base\")\n",
    "\n",
    "W2V=gensim.models.Word2Vec.load(\"W2V_all.model\")\n",
    "import time\n",
    "import fats\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aaa3faf-3bc8-4efb-ba59-eac0680c7d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23799"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test=pickle.load(open('MLSUM_fr_test.pickle','rb'))\n",
    "#texte=[test.text[:10].values.tolist()[i].split('.') for i in range(10)]\n",
    "\n",
    "Paragraphes= pickle.load(open('Paragraphes.pickle','rb'))#[i.split('.') for i in test.text.values.tolist()]\n",
    "Paragraphes=functools.reduce(operator.iconcat, Paragraphes, [])\n",
    "len(Paragraphes)\n",
    "#Paragraphes[0]\n",
    "#resu=fats.Resume(Paragraphes,DL=True,choose_model='SMHA',camem=camem,tok='MLSUM_tokenizer.model')\n",
    "#fats.Resume(Paragraphes[48*2:49*2],DL=False,cpu=1,type_='TextRankBert',k=2,modele=camem,tok=\"MLSUM_tokenizer.model\",get_score_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97452e9-e0e0-4ef1-b5a4-4bab174631d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419\n",
      "347\n",
      "1.46 %\n"
     ]
    }
   ],
   "source": [
    "#resu=fats.Resume(Paragraphes,DL=False,cpu=2,type_='TextRankBert',k=2,modele=camem,tok=\"MLSUM_tokenizer.model\",get_score_only=True)\n",
    "#Paragraphes[251+47]\n",
    "longueur=[len(i) for i in Paragraphes]\n",
    "import numpy as np\n",
    "print(np.max(longueur))\n",
    "seuil=80\n",
    "nul=len([i for i in longueur if i>seuil])\n",
    "print(nul)\n",
    "print(round(nul/len(Paragraphes)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57111a1e-e234-4d14-8905-2e15da6b978d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "ME=fats.Make_Embedding(tok=CamembertTokenizer(\"MLSUM_tokenizer.model\"),cpu=1)\n",
    "input_ids,att_mask=ME.make_token(Paragraphes[251+47],1)\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dabc9-f354-4517-a102-62be9475ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "c=camem(torch.tensor(input_ids[0:int(len(input_ids)/2)]),\n",
    "           torch.tensor(att_mask[0:int(len(input_ids)/2)])).last_hidden_state.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b4e28-81e9-4c4f-b0af-617aace371d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if len(input_ids)>70: #Au-delà de 70 phrases, camembert plante. On vérifie que le paragraphe en contient moins puis\n",
    "    #on va découper le paragraphe pour que chaque bout fasse moins de 70\n",
    "    # d'abord il convient de trouver le chiffre tq len(input_ids)/chiffre<70\n",
    "    for i in range(2,100):\n",
    "        if (len(input_ids)/i)<70:\n",
    "            h=i\n",
    "            print(h)\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    #une fois qu'on a ce chiffre h on y va :\n",
    "    embeddings=[]\n",
    "    for i in range(h):\n",
    "        x_1=int(len(input_ids)*(i/h))\n",
    "        x_2=int(len(input_ids)*((i+1)/h))\n",
    "        print(x_1,x_2)\n",
    "        embeddings.append(camem(torch.tensor(input_ids[x_1:x_2]),\n",
    "           torch.tensor(att_mask[x_1:x_2])).last_hidden_state.detach())\n",
    "    embeddings=torch.cat(embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d73b51c-1137-4e10-8cf9-186c2f4f741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 512, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(embeddings).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9122e42-c462-4a23-80a6-e52f08eac723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax=plt.subplots(figsize=(16,12))\n",
    "ax.hist(longueur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a2f7034-988f-40b8-a3e2-17f14b9c3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0317,  0.1234,  0.0652,  ..., -0.0192, -0.0331, -0.1243],\n",
       "         [-0.0206,  0.2380,  0.0225,  ..., -0.0392,  0.0044, -0.1620],\n",
       "         [-0.0927,  0.1113,  0.0838,  ...,  0.0675, -0.0221, -0.1592],\n",
       "         ...,\n",
       "         [-0.0286,  0.0901,  0.1715,  ...,  0.0044, -0.0259, -0.1014],\n",
       "         [-0.0585,  0.1646,  0.0774,  ..., -0.0571, -0.0480, -0.1135],\n",
       "         [-0.0290,  0.1889,  0.0935,  ...,  0.0064, -0.0407, -0.1483]]),\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEB=fats.TextRank(\"MLSUM_tokenizer.model\",cpu=1).make_embedding_bert\n",
    "MEB(Paragraphes[251+47],camem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d0ab285-df37-421d-b152-f04e06ae5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s=time.time()\n",
    "ms=fats.BERTScore(tok=\"MLSUM_tokenizer.model\",cpu=1).make_score\n",
    "#print(ms(Paragraphes[251+47]))\n",
    "#bs.make_score(Paragraphes[251+47])\n",
    "#(time.time()-s)/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0f12ae-4c29-49f4-b6b8-93c0857bfa04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 7, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rendu=pickle.load(open('BSR_sortie.pickle','rb'))#[] if \n",
    "rendu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c15370-f0c2-46c5-a14d-6fd4c1bfda02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 393/23148 [13:10<16:22:27,  2.59s/it]"
     ]
    }
   ],
   "source": [
    "rendu=pickle.load(open('BSR_sortie.pickle','rb'))#[] if \n",
    "print(len(rendu))\n",
    "ms=fats.BERTScore(tok=\"MLSUM_tokenizer.model\",cpu=1).make_score\n",
    "\n",
    "#pas=1\n",
    "#s\n",
    "for i in tqdm(range(len(rendu),len(Paragraphes))):\n",
    "    resu=ms(Paragraphes[i])\n",
    "    #fats.Resume(Paragraphes[(i*2):(i+pas)*2],DL=False,cpu=1,type_='TextRankBert',k=2,modele=camem,tok=\"MLSUM_tokenizer.model\",get_score_only=True)\n",
    "    rendu.append(resu)\n",
    "               \n",
    "    if i%50==0:\n",
    "        pickle.dump(rendu,open('BSR_sortie.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ca99b-9745-4435-a1d4-77ab60bc136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fats.make_U_resume(Paragraphes,cpu=1,type_='TextRankBert',k=2,modele=camem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8a7c90-be71-4fd5-b060-a39f4c922cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11899"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rendu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bae1e5-2374-43c5-abfa-6a09c337d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendu_2=functools.reduce(operator.iconcat, rendu, [])\n",
    "len(rendu_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16225e41-a6d3-47b0-b594-7f9cc5b65112",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendu[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070f61c-9de3-4c66-8559-f9e4db59504a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
