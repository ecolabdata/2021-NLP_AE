{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Bienvenue dans le notebook consacré au pipeline final du résumé"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "from tqdm import tqdm\r\n",
    "import pickle\r\n",
    "\r\n",
    "import os\r\n",
    "os.chdir(\"c:\\\\Users\\\\theo.roudil-valentin\\\\Documents\\\\Codes\") # A modifier, et mettre votre dossier correspondant !\r\n",
    "\r\n",
    "try:\r\n",
    "    os.chdir(\"2021-NLP_AE\\\\Theo\")\r\n",
    "except:\r\n",
    "    raise ValueError(\"Merci de décommenter la ligne verte au-dessus, et d'indiquer correctement le chemin vers le dossier contenant le git\")\r\n",
    "\r\n",
    "from transformers import CamembertTokenizer,CamembertModel\r\n",
    "tok=CamembertTokenizer('Model\\\\MLSUM_tokenizer.model')\r\n",
    "camem=CamembertModel.from_pretrained(\"camembert-base\")\r\n",
    "\r\n",
    "import gensim\r\n",
    "W2V=gensim.models.Word2Vec.load(\"Model\\\\W2V_all.model\")\r\n",
    "\r\n",
    "import fats #On importe le module contenant toutes les fonctions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exemple de la fonction finale de résumé !\r\n",
    "Comme vous pouvez le constater, la fonction de résumé a beaucoup d'options, et c'est normal !\r\n",
    "Dans l'idéal, vous pouvez sélectionner le modèle qui vous convient le mieux. J'ai essayé de laisser un maximum de choix aux utilisateurs. \r\n",
    "\r\n",
    "**Attention** Cette fonction est __profonde__, autrement dit, elle est basée sur un grand nombre d'autres fonctions ou suites ou classes de fonctions, qui sont toutes dans le module **fats.py** (à télécharger impérativement donc). La modification, ou même la compréhension de cette fonction et de tout ce sur quoi elle repose vous demandera du temps. J'ai, dans la mesure du possible, laisser le maximum d'indication. Les fonctions du module proviennent toutes d'un travail préliminaire, dont vous pouvez retrouver les codes dans le dossier **Exploration**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Il faut que P soit une liste de listes de phrases, donc on se débrouille pour que ce soit le cas\r\n",
    "P=pickle.load(open('Paragraphes_exemple.pickle','rb')) #Ajoutez votre propre liste, ou décommenter les suivantes (par deux) pour exemple\r\n",
    "\r\n",
    "#P=pickle.load(open('Paragraphes_exemple.pickle','rb'))\r\n",
    "\r\n",
    "#P=pickle.load(open('liste.pickle','rb')) #liste de Paragraphes\r\n",
    "#P=[i.split('.') for i in P.tolist()] # à activer si on a une liste de paragraphes qui ne soit pas de type liste (array), à commenter sinon\r\n",
    "\r\n",
    "# On lance par exemple pour les 3 premiers éléments\r\n",
    "resu,text_2=fats.Resume(texte=P,\r\n",
    "                 DL=False, # True si on veut utiliser des modèles de Deep Learning, False sinon\r\n",
    "                 cpu=1, #le nombre de cpu à utiliser, préférez peu de CPU, pour la mémoire\r\n",
    "                 type_='TextRankBert', #le nom du modèle, si DL=False\r\n",
    "                 k=2, #Le nombre de phrases\r\n",
    "                 choose_model=None, #le nom du modèle de Deep Learning, le cas échéant\r\n",
    "                 tok='Model\\\\MLSUM_tokenizer.model', #le nom du tokenizer\r\n",
    "                 modele=camem, #modèle CamemBERT ou W2V selon le modèle choisi\r\n",
    "                 get_score_only=False,# est-ce qu'on veut juste le score et pas directement les phrases\r\n",
    "                 s=True,vs=12000,sp=1,tr=False,t=True,seuil=2,lem=False,sc=3,\r\n",
    "                 weights=True,alpha=0.2,frac=0.25)\r\n",
    "print(resu) "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.7 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "interpreter": {
   "hash": "e34048b0732ca5da544928c261c6b0ec51b7f57de61b26cf2eebb756a9ee889a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}