{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.7 64-bit ('venv': venv)"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "version": "3.6.7",
      "name": "python",
      "pygments_lexer": "ipython3",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "creator": "TRoudil",
    "associatedRecipe": "compute_base_classif_RF",
    "createdOn": 1620402505202,
    "tags": [
      "recipe-editor"
    ],
    "modifiedBy": "TRoudil",
    "customFields": {},
    "interpreter": {
      "hash": "e34048b0732ca5da544928c261c6b0ec51b7f57de61b26cf2eebb756a9ee889a"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Traitement des résultats du Kmeans"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17 août 2021** : j'ai modifié l'ensemble de ce qui vient de dataiku. Normalement, cela devrait fonctionner partout. Des erreurs peuvent rester néanmoins, soyez vigilant.\r\n",
        "\r\n",
        "**11 mai 2021** : on utilise la version 2 de la base finale, donc la version 3 des modèles.\r\n",
        "\r\n",
        "**Qu'est-ce qui change ?** Après la version 2 (en date du 08/05/21), on généralise encore la fonction qui construit l'indicatrice sommaire : on parcourt les différents mots du début du sommaire, on lâche un peu de mou dans la sélection du sommaire, on sélectionne brutalement les 200 lignes après l'apparition du mot débutant le sommaire si besoin etc... Bon, même la détection de l'apparition est sujette à caution : parfois, les indices semblent lointains. C'est pourquoi on a rajouter une restriction. Si l'indice du sommaire (c'est-à-dire le numéro de la ligne où débuterait le sommaire) est trop élevé (et que l'on a toujours pas de sommaire pour l'étude), on ne prend pas de sommaire et on accepte (pour le moment) de laisser cette étude vide finalement. Cette restriction est basée sur l'indice moyen des études ayant un sommaire correct en bout de pipeline, qui est de 44, pour être moins rigide nous avons fixé ce seuil à 100. De même parfois, les indicatrices sommaires sont trop petites, donc si en première approche il y a moins de 50 lignes indiquées, on poursuit avec la nouvelle approche.\r\n",
        "En soi, on pourrait justement dire que le sommaire se trouve probablement dans le 400 premières lignes (par exemple) et ainsi prendre encore plus brutalement ces lignes, mais cela reste à discuter."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "import pandas as pd, numpy as np\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import time\r\n",
        "from unidecode import unidecode\r\n",
        "import re\r\n",
        "import pickle\r\n",
        "import os\r\n",
        "\r\n",
        "# Vous pouvez indiquer votre chemin ici\r\n",
        "# os.chdir(\"C:\\\\Users\\\\theo.roudil-valentin\\\\Documents\\\\Codes\")\r\n",
        "\r\n",
        "# Sinon lancez simplement, cela reprendre vos config si vous avez déjà fait tourner les codes précédents\r\n",
        "cwd=os.getcwd()\r\n",
        "cwd\r\n",
        "if cwd.split('\\\\')[-1] not in ['Bagging_model','Extraction_sommaire']:\r\n",
        "    try:\r\n",
        "        os.chdir(\"2021-NLP_AE\\\\Data\\\\Bagging_model\")\r\n",
        "    except:\r\n",
        "        os.chdir(\"2021-NLP_AE\\\\Pipeline\\\\Extraction_sommaire\")\r\n",
        "\r\n",
        "base_finale=pickle.load(open(\"/base_pour_Bagging_final_new.pickle\",'rb'))\r\n",
        "print('Il y a ',len(np.unique(base_finale.num_etude)),\"études\")\r\n",
        "print(base_finale.label_k.sum()/len(base_finale)*100)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "changement\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "300000/len(base_finale)*100\r\n",
        "base_finale.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12.279812724669407"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "len(base_finale[base_finale.ind_sommaire==1][base_finale.label_k==1])/len(base_finale)*100"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\Users\\theo.roudil-valentin\\venv\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1597055137177787"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "len(base_finale[base_finale.label_k==0])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "515683\n",
              "Index(['phrase', 'num_etude', 'phrase_2', '0', 'ventre_0', 'ventre_1',\n",
              "       'ventre_2', 'ventre_3', 'ventre_4', 'ventre_5', 'ventre_6', 'ventre_7',\n",
              "       'ventre_8', 'ventre_9', 'ventre_10', 'ventre_11', '33', '34', '35',\n",
              "       '36', '37', '38', '39', 'f_mots', 'f_carac', 'html_carac',\n",
              "       'ind_sommaire', 'sommaire_longueur', 'sommaire_int', 'caractere_spec',\n",
              "       'label_k_4'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention à bien vérifier la correspondance des labels du Kmeans !!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Vérification des labelisés 1 par le Kmeans"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATTENTION** Pour la version 3, les labels Kmeans sont inversés !\r\n",
        "\r\n",
        "**Si vous ré-adaptez ce code : faites attention à quel groupe le Kmeans a labellisé comme 0 et 1 !**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "N=10000\r\n",
        "\r\n",
        "for i in base_finale[base_finale.label_k_4==1].iloc[:N,:].index:\r\n",
        "    print(\"Indice :\",i,\"\\n\",base_finale.phrase_2[i])"
      ],
      "outputs": [],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bon sur l'échantillon de 1000, les labelisés 1 semblent être tous des \"non-titres\", donc c'est super !"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Vérification des labelisés 0 par le Kmeans\n",
        "### 1.2.1 Essai sur sous-ensemble"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "N=0#10000\r\n",
        "\r\n",
        "for i in base_finale[base_finale.ind_sommaire==1][base_finale.label_k==0].iloc[N:N+10000,:].index:\r\n",
        "    print(\"Indice :\",i,\"\\n\",base_finale.phrase_2[i])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bon sur l'échantillon de 1000, les labelisés 1 semblent être tous des \"non-titres\", donc c'est super !"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Vérification des labelisés 0 par le Kmeans\n",
        "### 1.2.1 Essai sur sous-ensemble"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "N=0#10000\r\n",
        "\r\n",
        "for i in base_finale[base_finale.ind_sommaire==1][base_finale.label_k==0].iloc[N:N+10000,:].index:\r\n",
        "    print(\"Indice :\",i,\"\\n\",base_finale.phrase_2[i])"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ATTENTION** La cellule qui suit a pour but de nettoyer les mauvaises labellisations effectuées par le Kmeans. Elle concerne donc NOTRE projet, très probablement pas le votre. Donc faîtes attention quand vous le lancez.\r\n",
        "\r\n",
        "Comme vous pouvez le constater, on essaie ici de chercher les index des unités étranges, pour forcer leur label à 0."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "source": [
        "base=base_finale.iloc[:296183,:]\r\n",
        "c=[1 if (base.ind_sommaire[i]==1) and (base.label_k[i]==1) else 0 for i in base.index]\r\n",
        "#print(len(c))\r\n",
        "c_index=[i for i in base.index if base.phrase_2[i]=='^' or base.phrase_2[i]==base.iloc[141175,:].phrase_2]\r\n",
        "for i in c_index:\r\n",
        "    c[i]=0\r\n",
        "#print(len(c))\r\n",
        "c[29533:29584]=np.zeros(29584-29533)\r\n",
        "#print(len(c))\r\n",
        "c[29901:131462]=np.zeros(131462-29901)\r\n",
        "#print(len(c))\r\n",
        "c[141223:162733]=np.zeros(162733-141223)\r\n",
        "#print(len(c))\r\n",
        "#c[162550:162535]=np.zeros(162535-162550)\r\n",
        "c[177975:186252]=np.zeros(186252-177975)\r\n",
        "#print(len(c))\r\n",
        "c[203924:247583]=np.zeros(247583-203924)\r\n",
        "#print(len(c))\r\n",
        "c[284870:285811]=np.zeros(285811-284870)\r\n",
        "#print(len(c))\r\n",
        "c[285860:296183]=np.zeros(296183-285860)\r\n",
        "#print(len(c))\r\n",
        "base['label']=c\r\n",
        "base=base_finale.iloc[:296183,:]\r\n",
        "c=[1 if (base.ind_sommaire[i]==1) and (base.label_k[i]==1) else 0 for i in base.index]\r\n",
        "#print(len(c))\r\n",
        "c_index=[i for i in base.index if base.phrase_2[i]=='^' or base.phrase_2[i]==base.iloc[141175,:].phrase_2]\r\n",
        "for i in c_index:\r\n",
        "    c[i]=0\r\n",
        "#print(len(c))\r\n",
        "c[29533:29584]=np.zeros(29584-29533)\r\n",
        "#print(len(c))\r\n",
        "c[29901:131462]=np.zeros(131462-29901)\r\n",
        "#print(len(c))\r\n",
        "c[141223:162733]=np.zeros(162733-141223)\r\n",
        "#print(len(c))\r\n",
        "#c[162550:162535]=np.zeros(162535-162550)\r\n",
        "c[177975:186252]=np.zeros(186252-177975)\r\n",
        "#print(len(c))\r\n",
        "c[203924:247583]=np.zeros(247583-203924)\r\n",
        "#print(len(c))\r\n",
        "c[284870:285811]=np.zeros(285811-284870)\r\n",
        "#print(len(c))\r\n",
        "c[285860:296183]=np.zeros(296183-285860)\r\n",
        "#print(len(c))\r\n",
        "base['label']=c\r\n",
        "base"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-391cfff0ded8>:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  base['label']=c\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   phrase  num_etude  \\\n",
              "0                         <title>EI Munchhouse_V3</title>    1003691   \n",
              "1       <h1><a name=\"bookmark0\"></a><span class=\"font2...    1003691   \n",
              "2       <p><span class=\"font20\" style=\"font-weight:bol...    1003691   \n",
              "3       <p><span class=\"font14\">Agence Aquitaine</span...    1003691   \n",
              "4               <p><span class=\"font14\">SAFEGE</span></p>    1003691   \n",
              "...                                                   ...        ...   \n",
              "296178  <li>\\n<p><span class=\"font6\">■ Les aléas d’acc...     106905   \n",
              "296179  <li>\\n<p><span class=\"font6\">■ Les aléas d’ino...     106905   \n",
              "296180  <p><a name=\"bookmark921\"></a><span class=\"font...     106905   \n",
              "296181  <p><span class=\"font6\">Le territoire de La Jai...     106905   \n",
              "296182  <p><span class=\"font6\" style=\"font-weight:bold...     106905   \n",
              "\n",
              "                                                 phrase_2         0  ventre_0  \\\n",
              "0                                        EI Munchhouse_V3  0.000000  0.007237   \n",
              "1                                                      06  0.048998  0.021633   \n",
              "2                                                    2019  0.022272  0.011876   \n",
              "3                                        Agence Aquitaine  0.001114  0.011479   \n",
              "4                                                  SAFEGE  0.001114  0.007209   \n",
              "...                                                   ...       ...       ...   \n",
              "296178    \\n■ Les aléas d’accumulation de gaz dangereux ;  0.001114  0.026082   \n",
              "296179  \\n■ Les aléas d’inondation localisée ou de rem...  0.001114  0.051407   \n",
              "296180                          Sur le territoire d’étude  0.001114  0.031688   \n",
              "296181  Le territoire de La Jaille-Yvon n’est pas cons...  0.001114  0.060613   \n",
              "296182  Le risque minier peut être considéré comme fai...  0.001114  0.031383   \n",
              "\n",
              "        ventre_1  ventre_2  ventre_3  ventre_4  ventre_5  ...   39    f_mots  \\\n",
              "0       0.001262  0.209389  0.139448  0.353363  0.130169  ...  0.0  0.002841   \n",
              "1       0.027711  0.201385  0.156727  0.325818  0.098187  ...  0.0  0.000000   \n",
              "2       0.013931  0.204308  0.128357  0.321930  0.092321  ...  0.0  0.000000   \n",
              "3       0.006782  0.209288  0.135008  0.264427  0.141187  ...  0.0  0.002841   \n",
              "4       0.006764  0.206694  0.135066  0.262446  0.141680  ...  0.0  0.000000   \n",
              "...          ...       ...       ...       ...       ...  ...  ...       ...   \n",
              "296178  0.008910  0.202207  0.138018  0.272561  0.147820  ...  0.0  0.019886   \n",
              "296179  0.008833  0.197512  0.134242  0.262987  0.145136  ...  0.0  0.048295   \n",
              "296180  0.027998  0.204303  0.149004  0.247218  0.107150  ...  0.0  0.008523   \n",
              "296181  0.006379  0.202552  0.128435  0.253922  0.137603  ...  0.0  0.056818   \n",
              "296182  0.013630  0.204813  0.134572  0.237378  0.093233  ...  0.0  0.019886   \n",
              "\n",
              "         f_carac  html_carac  ind_sommaire  sommaire_longueur  sommaire_int  \\\n",
              "0       0.006463    0.005215           0.0                0.0           0.0   \n",
              "1       0.000431    0.027724           0.0                0.0           0.0   \n",
              "2       0.001293    0.014548           0.0                0.0           0.0   \n",
              "3       0.006463    0.010705           0.0                0.0           0.0   \n",
              "4       0.002154    0.007960           0.0                0.0           0.0   \n",
              "...          ...         ...           ...                ...           ...   \n",
              "296178  0.019388    0.021136           1.0                0.0           0.0   \n",
              "296179  0.044808    0.037332           1.0                0.0           0.0   \n",
              "296180  0.010340    0.034312           1.0                0.0           0.0   \n",
              "296181  0.056010    0.041998           1.0                0.0           0.0   \n",
              "296182  0.021112    0.026901           1.0                0.0           0.0   \n",
              "\n",
              "        caractere_spec  label_k_4  label  \n",
              "0                  0.0          0    0.0  \n",
              "1                  0.0          0    0.0  \n",
              "2                  0.0          0    0.0  \n",
              "3                  0.0          0    0.0  \n",
              "4                  0.0          0    0.0  \n",
              "...                ...        ...    ...  \n",
              "296178             1.0          0    0.0  \n",
              "296179             1.0          0    0.0  \n",
              "296180             0.0          0    0.0  \n",
              "296181             0.0          0    0.0  \n",
              "296182             0.0          0    0.0  \n",
              "\n",
              "[296183 rows x 32 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>num_etude</th>\n",
              "      <th>phrase_2</th>\n",
              "      <th>0</th>\n",
              "      <th>ventre_0</th>\n",
              "      <th>ventre_1</th>\n",
              "      <th>ventre_2</th>\n",
              "      <th>ventre_3</th>\n",
              "      <th>ventre_4</th>\n",
              "      <th>ventre_5</th>\n",
              "      <th>...</th>\n",
              "      <th>39</th>\n",
              "      <th>f_mots</th>\n",
              "      <th>f_carac</th>\n",
              "      <th>html_carac</th>\n",
              "      <th>ind_sommaire</th>\n",
              "      <th>sommaire_longueur</th>\n",
              "      <th>sommaire_int</th>\n",
              "      <th>caractere_spec</th>\n",
              "      <th>label_k_4</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;title&gt;EI Munchhouse_V3&lt;/title&gt;</td>\n",
              "      <td>1003691</td>\n",
              "      <td>EI Munchhouse_V3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007237</td>\n",
              "      <td>0.001262</td>\n",
              "      <td>0.209389</td>\n",
              "      <td>0.139448</td>\n",
              "      <td>0.353363</td>\n",
              "      <td>0.130169</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.005215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;h1&gt;&lt;a name=\"bookmark0\"&gt;&lt;/a&gt;&lt;span class=\"font2...</td>\n",
              "      <td>1003691</td>\n",
              "      <td>06</td>\n",
              "      <td>0.048998</td>\n",
              "      <td>0.021633</td>\n",
              "      <td>0.027711</td>\n",
              "      <td>0.201385</td>\n",
              "      <td>0.156727</td>\n",
              "      <td>0.325818</td>\n",
              "      <td>0.098187</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000431</td>\n",
              "      <td>0.027724</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;p&gt;&lt;span class=\"font20\" style=\"font-weight:bol...</td>\n",
              "      <td>1003691</td>\n",
              "      <td>2019</td>\n",
              "      <td>0.022272</td>\n",
              "      <td>0.011876</td>\n",
              "      <td>0.013931</td>\n",
              "      <td>0.204308</td>\n",
              "      <td>0.128357</td>\n",
              "      <td>0.321930</td>\n",
              "      <td>0.092321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001293</td>\n",
              "      <td>0.014548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;p&gt;&lt;span class=\"font14\"&gt;Agence Aquitaine&lt;/span...</td>\n",
              "      <td>1003691</td>\n",
              "      <td>Agence Aquitaine</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.011479</td>\n",
              "      <td>0.006782</td>\n",
              "      <td>0.209288</td>\n",
              "      <td>0.135008</td>\n",
              "      <td>0.264427</td>\n",
              "      <td>0.141187</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002841</td>\n",
              "      <td>0.006463</td>\n",
              "      <td>0.010705</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;p&gt;&lt;span class=\"font14\"&gt;SAFEGE&lt;/span&gt;&lt;/p&gt;</td>\n",
              "      <td>1003691</td>\n",
              "      <td>SAFEGE</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.007209</td>\n",
              "      <td>0.006764</td>\n",
              "      <td>0.206694</td>\n",
              "      <td>0.135066</td>\n",
              "      <td>0.262446</td>\n",
              "      <td>0.141680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002154</td>\n",
              "      <td>0.007960</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296178</th>\n",
              "      <td>&lt;li&gt;\\n&lt;p&gt;&lt;span class=\"font6\"&gt;■ Les aléas d’acc...</td>\n",
              "      <td>106905</td>\n",
              "      <td>\\n■ Les aléas d’accumulation de gaz dangereux ;</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.026082</td>\n",
              "      <td>0.008910</td>\n",
              "      <td>0.202207</td>\n",
              "      <td>0.138018</td>\n",
              "      <td>0.272561</td>\n",
              "      <td>0.147820</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019886</td>\n",
              "      <td>0.019388</td>\n",
              "      <td>0.021136</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296179</th>\n",
              "      <td>&lt;li&gt;\\n&lt;p&gt;&lt;span class=\"font6\"&gt;■ Les aléas d’ino...</td>\n",
              "      <td>106905</td>\n",
              "      <td>\\n■ Les aléas d’inondation localisée ou de rem...</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.051407</td>\n",
              "      <td>0.008833</td>\n",
              "      <td>0.197512</td>\n",
              "      <td>0.134242</td>\n",
              "      <td>0.262987</td>\n",
              "      <td>0.145136</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.048295</td>\n",
              "      <td>0.044808</td>\n",
              "      <td>0.037332</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296180</th>\n",
              "      <td>&lt;p&gt;&lt;a name=\"bookmark921\"&gt;&lt;/a&gt;&lt;span class=\"font...</td>\n",
              "      <td>106905</td>\n",
              "      <td>Sur le territoire d’étude</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.031688</td>\n",
              "      <td>0.027998</td>\n",
              "      <td>0.204303</td>\n",
              "      <td>0.149004</td>\n",
              "      <td>0.247218</td>\n",
              "      <td>0.107150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008523</td>\n",
              "      <td>0.010340</td>\n",
              "      <td>0.034312</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296181</th>\n",
              "      <td>&lt;p&gt;&lt;span class=\"font6\"&gt;Le territoire de La Jai...</td>\n",
              "      <td>106905</td>\n",
              "      <td>Le territoire de La Jaille-Yvon n’est pas cons...</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.060613</td>\n",
              "      <td>0.006379</td>\n",
              "      <td>0.202552</td>\n",
              "      <td>0.128435</td>\n",
              "      <td>0.253922</td>\n",
              "      <td>0.137603</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.056818</td>\n",
              "      <td>0.056010</td>\n",
              "      <td>0.041998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296182</th>\n",
              "      <td>&lt;p&gt;&lt;span class=\"font6\" style=\"font-weight:bold...</td>\n",
              "      <td>106905</td>\n",
              "      <td>Le risque minier peut être considéré comme fai...</td>\n",
              "      <td>0.001114</td>\n",
              "      <td>0.031383</td>\n",
              "      <td>0.013630</td>\n",
              "      <td>0.204813</td>\n",
              "      <td>0.134572</td>\n",
              "      <td>0.237378</td>\n",
              "      <td>0.093233</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019886</td>\n",
              "      <td>0.021112</td>\n",
              "      <td>0.026901</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>296183 rows × 32 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "collapsed": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#c_index\r\n",
        "#base[base.phrase_2==base.iloc[141175,:].phrase_2]\r\n",
        "base.label.sum()/base.shape[0]*100"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in base[base.label==1].index:\r\n",
        "    print(\"Indice :\",i,\"\\n\",\"base.phrase_2[i]\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        " Désormais, on a une nouvelle variable : label.\r\n",
        "\"Elle est le croisement de indicatrice_sommaire et label_k puis passe dans un nouveau nettoyage. On peut donc donner les anciennes variables utilisées pour construire notre nouvel algorithme.\"\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classification supervisée\r\n",
        "\r\n",
        "Attention, désormais, titres ==1 et non_titres==0"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(base.iloc[:,3:-1],base.loc[:,'label'],test_size=0.25)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Train : proportion de 1 :\",round(y_train.sum()/len(y_train)*100,3),\" ; de 0 :\",round((1-y_train.sum()/len(y_train))*100,3))\r\n",
        "print(\"Test : proportion de 1 :\",round(y_test.sum()/len(y_test)*100,3),\" ; de 0 :\",round((1-y_test.sum()/len(y_test))*100,3))\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arbre de décision"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "k=0 # On a plus besoin d'étudier le k\r\n",
        "X_train_2=X_train.iloc[:,:(X_train.shape[1]-k)]\r\n",
        "X_test_2=X_test.iloc[:,:(X_train.shape[1]-k)]\r\n",
        "\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "DTC = DecisionTreeClassifier(class_weight=\"balanced\")\r\n",
        "DTC.fit(X_train_2, y_train)\r\n",
        "print(\"Score train :\",round(DTC.score(X_train_2,y_train),3))\r\n",
        "print(\"Score test :\",round(DTC.score(X_test_2,y_test),3))\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "confusion_matrix(y_test,DTC.predict(X_test_2))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Forêt aléatoire"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "################ NE PAS LANCER !\\n\",\r\n",
        "######### De même, plus besoin d'étudier cela, je laisse pour l'historique du travail\\n\",\r\n",
        "absi=[]\r\n",
        "ordo=[]\r\n",
        "ordo_test=[]\r\n",
        "\r\n",
        "for i in range(1,X_train.shape[1]):\r\n",
        "    X_train_2=X_train.iloc[:,:i]\r\n",
        "    X_test_2=X_test.iloc[:,:i]\r\n",
        "\r\n",
        "    DTC = RandomForestClassifier(n_estimators=10,verbose=0,class_weight=\"balanced\")\r\n",
        "    DTC.fit(X_train_2, y_train)\r\n",
        "\r\n",
        "    ordo.append(DTC.score(X_train_2,y_train))\r\n",
        "    ordo_test.append(DTC.score(X_test_2,y_test))\r\n",
        "    absi.append(i)\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "f,a=plt.subplots(1,figsize=(12,6))\r\n",
        "a.plot(absi,ordo)\r\n",
        "a.plot(absi,ordo_test)\r\n",
        "a.set(xlabel=\"Nombre de variables\",ylabel='Score'\r\n",
        "      title='Score de la random forest en fonction du nombre de variables')\r\n",
        "plt.legend(['train','test'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "############## On passe aux forêts :\\n\",\r\n",
        "n=10 # On essaie avec 10 estimateurs\\n\",\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "RFC = RandomForestClassifier(n_estimators=n,verbose=0,class_weight=\"balanced\")\r\n",
        "RFC.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(\"Score train :\",round(RFC.score(X_train,y_train),3))\r\n",
        "print(\"Score test :\",round(RFC.score(X_test,y_test),3))\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(\"Matrice de confusion sur le train \\n\",confusion_matrix(y_train,RFC.predict(X_train)))\r\n",
        "print(\"Matrice de confusion sur le test \\n\",confusion_matrix(y_test,RFC.predict(X_test)))\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "On fait encore des erreurs, donc on poursuit, on augmente n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "n=100 # On essaie avec 100 estimateurs\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "RFC = RandomForestClassifier(n_estimators=n,verbose=0,class_weight=\"balanced\")\r\n",
        "RFC.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(\"Score train :\",round(RFC.score(X_train,y_train),3))\r\n",
        "print(\"Score test :\",round(RFC.score(X_test,y_test),3))\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(\"Matrice de confusion sur le train \\n\",confusion_matrix(y_train,RFC.predict(X_train)))\r\n",
        "print(\"Matrice de confusion sur le test \\n\",confusion_matrix(y_test,RFC.predict(X_test)))\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Malgré la multiplication par 10 du nombre d'estimateurs, on ne réussit pas à classifier parfaitement. Poursuivons.\"\r\n",
        "### Forêt aléatoire et bagging\r\n",
        "On va faire 100 fois la sélection du meilleur estimateur parmi 100 forêt aléatoire estimée."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.ensemble import BaggingClassifier\r\n",
        "\r\n",
        "RFC = RandomForestClassifier(n_estimators=100,verbose=0,class_weight=\"balanced\")#,bootstrap=False) #à voir\r\n",
        "Bagging = BaggingClassifier(RFC,n_estimators=100,verbose=0)\r\n",
        "Bagging.fit(X_train, y_train)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Score train :\",round(Bagging.score(X_train,y_train),3))\r\n",
        "print(\"Score test :\",round(Bagging.score(X_test,y_test),3))\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(\"Matrice de confusion sur le train \\n\",confusion_matrix(y_train,Bagging.predict(X_train)))\r\n",
        "print(\"Matrice de confusion sur le test \\n\",confusion_matrix(y_test,Bagging.predict(X_test)))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Malgré le Bagging, on ne réussit pas à classer **parfaitement**."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base['label_rf']=Bagging.predict(base.iloc[:,3:-1])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in base[base.label_rf==1].phrase_2:\r\n",
        "        print(i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "(base.label_rf.sum()/len(base))*100"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pickle\r\n",
        "dico_Bagging={}\r\n",
        "dico_Bagging['train']=[X_train,y_train]\r\n",
        "dico_Bagging['test']=[X_test,y_test]\r\n",
        "dico_Bagging['base']=base\r\n",
        "dico_Bagging['modele']=Bagging\r\n",
        "pickle.dump(dico_Bagging,open(\"dico_Bagging_new.pickle\",'wb'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Prédiction supervisée de l'ensemble de notre base"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "########### Chargement du modèle\\n\",\r\n",
        "import pandas as pd, numpy as np\r\n",
        "import time\r\n",
        "import pickle\r\n",
        "dico=pickle.load(open(\"dico_Bagging_new.pickle\",'rb'))\r\n",
        "clf_titres_fin=dico['modele']"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_finale=pickle.load(open(\"base_pour_Bagging_final_new.pickle\",'rb'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention à bien laisser la dernière variable de la grosse base puisque le modèle utilise label_k pour prédire label"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "start=time.time()\r\n",
        "pred=Bagging.predict(base_finale.iloc[:,3:])\r\n",
        "end=time.time()\r\n",
        "print(\"Durée de la prédiction :\",round((end-start)/60,2),\"minutes\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(pred.shape,base_finale.shape)\r\n",
        "base_finale['label_RF']=pred\r\n",
        "base_finale.label_RF.sum()/len(base_finale)*100"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in base_finale[base_finale.label_RF==1].iloc[:,:].phrase_2:\r\n",
        "    print(i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pickle.dump(base_finale.loc[:,['num_etude','phrase_2','label_RF']],open(\"label_RF_new.pickle\",'wb'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Active learning\r\n",
        "\r\n",
        "Ici, on va essayer de partir de l'aval du processus, pour remonter et modifier les étapes délicates. Ces changements ont déjà été intégrés plus haut, donc je le laisse pour information.\r\n",
        "\r\n",
        "## 4.1 Première boucle"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "N=300000\r\n",
        "train_active=base_finale.iloc[base.shape[0]:base.shape[0]+N,:]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in train_active.index:\r\n",
        "    if train_active.label_RF[i]==1:\r\n",
        "        print(\"\\nIndice :\",i-base.shape[0])\r\n",
        "        print(train_active.loc[i,'phrase_2'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "c=train_active.label_RF.values\r\n",
        "c[2107:26521]=np.zeros(26521-2107)\r\n",
        "c[277263:278418]=np.zeros(278418-277263)\r\n",
        "c[278867:280569]=np.zeros(280569-278867)\r\n",
        "c[280603:294368]=np.zeros(294368-280603)\r\n",
        "train_active['label']=c\r\n",
        "train_active"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vide=[i for i in np.unique(train_active.num_etude) if train_active[train_active.num_etude==i].label_RF.sum()==0]\r\n",
        "vide"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#for i in vide:\\n\",\r\n",
        "i=vide[-1]\r\n",
        "print(\"########################################## \\n\",i,\"\\n\")\r\n",
        "for k in train_active[train_active.num_etude==i].phrase_2:\r\n",
        "    print(list(train_active[train_active.num_etude==i].phrase_2).index(k))\r\n",
        "    print(k,\"\\n\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "c=np.zeros(len(train_active[train_active.num_etude==i].phrase_2))\r\n",
        "c[18:624]=np.ones(624-18)\r\n",
        "idx=train_active[train_active.num_etude==i].index[0]\r\n",
        "train_active.loc[18+idx:624+idx,'label']=1\r\n",
        "train_active[train_active.num_etude==i][18:100]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "presque_vide=[i for i in np.unique(train_active.num_etude) if (train_active[train_active.num_etude==i].label_RF.sum()>0) and (train_active[train_active.num_etude==i].label_RF.sum()<50)]\r\n",
        "presque_vide"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "i=presque_vide[-1]\r\n",
        "print(\"########################################## \\n\",i,\"\\n\")\r\n",
        "for k in train_active[train_active.num_etude==i].phrase_2:\r\n",
        "    print(list(train_active[train_active.num_etude==i].phrase_2).index(k))\r\n",
        "    print(k,\"\\n\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "idx=train_active[train_active.num_etude==109735].index[0]\r\n",
        "train_active.loc[36+idx:257+idx,'label']=1\r\n",
        "train_active[train_active.num_etude==109735][36:100]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "idx=train_active[train_active.num_etude==1094735].index[0]\r\n",
        "train_active.loc[53+idx:551+idx,'label']=1\r\n",
        "train_active.loc[53+idx:551+idx,:]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_active=pd.concat([base.iloc[:,:-2],train_active.iloc[:,:-2]])\r\n",
        "y_active=list(base.loc[:,'label_rf'])+list(train_active.loc[:,'label'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_active['label']=y_active"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in base_active.index:\r\n",
        "    try:\r\n",
        "        if type(float(base_active.loc[i,'phrase_2']))==float:\r\n",
        "            print(base_active.loc[i,'phrase_2'])\r\n",
        "            base_active.loc[i,'label']=0\r\n",
        "    except:\r\n",
        "        continue"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(base_active.iloc[:,3:],base_active.iloc[:,-1],test_size=0.25,shuffle=True)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "n=100 # On essaie avec 100 estimateurs\\n\",\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "RFC = RandomForestClassifier(n_estimators=n,verbose=0,class_weight=\"balanced\")\r\n",
        "RFC.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(\"Score train :\",round(RFC.score(X_train,y_train),3))\r\n",
        "print(\"Score test :\",round(RFC.score(X_test,y_test),3))\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "print(\"Matrice de confusion sur le train \\n\",confusion_matrix(y_train,RFC.predict(X_train)))\r\n",
        "print(\"Matrice de confusion sur le test \\n\",confusion_matrix(y_test,RFC.predict(X_test)))\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dico_Bagging={}\r\n",
        "dico_Bagging['train']=[X_train,y_train]\r\n",
        "dico_Bagging['test']=[X_test,y_test]\r\n",
        "dico_Bagging['base']=base_active.iloc[:,:3]\r\n",
        "dico_Bagging['modele']=RFC\r\n",
        "pickle.dump(dico_Bagging,open(\"dico_RF_active.pickle\",'wb'))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### On check les nouveaux résultats"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "base_finale"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_active=RFC.predict(base_finale.iloc[:,3:-1])\r\n",
        "base_finale['label_active']=pred_active"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for i in base_finale[base_finale.label_active==1].phrase_2:\r\n",
        "    print(i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vide=[i for i in np.unique(base_finale.num_etude) if base_finale[base_finale.num_etude==i].label_active.sum()==0]\r\n",
        "len(vide)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "train_active[train_active.num_etude==1098190][50:150]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vide\r\n",
        "#112862\r\n",
        "#196750\r\n",
        "#1008101\r\n",
        "#1078725\r\n",
        "#1259375\r\n",
        "#2072251 c'est un avis ???\r\n",
        "#2255947"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Analyse des titres non détectés (exploratoire, à ne pas faire tourner sauf exception)\r\n",
        "\r\n",
        "Cette partie concerne uniquement notre projet. Elle peut être intéressante pour le votre, mais cela est à vous de voir."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans un premier temps, quantifions la quantité de documents n'ayant pas de titres détectés."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vide=[i for i in np.unique(base_finale.num_etude) if base_finale[base_finale.num_etude==i].label_RF.sum()==0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "np.unique(base_finale.num_etude)[0]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "non_vide=[i for i in np.unique(base_finale.num_etude) if i not in vide]\r\n",
        "len(non_vide)/len(np.unique(base_finale.num_etude))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "index_vide=[True if base_finale.num_etude[i] in vide else False for i in base_finale.index]\r\n",
        "base_relou=base_finale[index_vide]\r\n",
        "base_relou"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(\"Proportion des labels kmeans chez les vides,\\nnon-titres (1) :\",round(base_relou.label_k.sum()/len(base_relou)*100,2))\r\n",
        "print(\"Proportion des labels kmeans chez les non vides,\\nnon-titres (1) :\",round(base_propre.label_k.sum()/len(base_propre)*100,2))\r\n",
        "print(\"Proportion des labels kmeans total,\\nnon-titres (1) :\",round(base_finale.label_k.sum()/len(base_finale)*100,2))\r\n",
        "numero=np.unique(base_relou.num_etude)\r\n",
        "k=0\r\n",
        "titres=list(base_relou[base_relou.label_k==1][base_relou.num_etude==numero[k]].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_relou.num_etude)\r\n",
        "k=0\r\n",
        "titres=list(base_relou[base_relou.ind_sommaire==1][base_relou.num_etude==numero[k]].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\\\nIndice :',titres.index(i),i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "base_relou[base_relou.ind_sommaire==1][base_relou.num_etude==numero[k]]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problème sur le clustering Kmeans, probablement du à ind_sommaire ?\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "len(base_relou),len(base_finale)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "index_nonvide=[bool(abs(i-1)) for i in index_vide]\r\n",
        "base_propre=base_finale[index_nonvide]\r\n",
        "distrib_nbligne_propre=[len(base_propre[base_propre.num_etude==i]) for i in np.unique(base_propre.num_etude)]\r\n",
        "print(\"Pourcentage d'études vides :\",round(len(non_vide)/len(np.unique(base_finale.num_etude))*100,2),\"%\")\r\n",
        "print('Les documents vides représentent',round(len(base_relou)/len(base_finale)*100,2),'% de la base pour la classification supervisée')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_propre.num_etude)\r\n",
        "k=8\r\n",
        "titres=list(base_propre[base_propre.label_k==1][base_propre.num_etude==numero[k]].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "distrib_nbligne_vide=[len(base_relou[base_relou.num_etude==i]) for i in np.unique(base_relou.num_etude)]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def stat_des(x,mo,k=2):\r\n",
        "    if mo=='mean':\r\n",
        "        y=np.mean(x)\r\n",
        "    elif mo=='std':\r\n",
        "        y=np.std(x)\r\n",
        "    elif mo=='med':\r\n",
        "        y=np.median(x)\r\n",
        "    else:\r\n",
        "        raise ValueError('Veuillez spécifier quel type de stat des vous voulez. Valeurs possibles : mean, std ou med')\r\n",
        "    z=round(y,k)\r\n",
        "    return z"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "figue,hache=plt.subplots(figsize=(18,12))\r\n",
        "#sns.kdeplot(distrib_nbligne_propre , bw = 0.5 , fill = True)\r\n",
        "#sns.kdeplot(distrib_nbligne_vide , bw = 0.5 , fill = True)\r\n",
        "sns.distplot(distrib_nbligne_propre)\r\n",
        "sns.distplot(distrib_nbligne_vide)\r\n",
        "\r\n",
        "#hache.hist(distrib_nbligne_propre,density=True,bins=20)\r\n",
        "#hache.hist(distrib_nbligne_vide,density=True,bins=20)\r\n",
        "plt.legend(['propre','vide'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant qu'on a analysé le problème et trouvé une source de problème, on repasse la base_relou à la moulinette pour voir si ça s'arrange"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "technique=['non technique',unidecode('Table des matières'.lower())]\r\n",
        "numero=np.unique(base_relou.num_etude)\r\n",
        "indice=[i for i in range(len(base_relou[base_relou.num_etude==numero[3]].phrase_2.values))\r\n",
        "    if np.sum([1 if som in unidecode(base_relou[base_relou.num_etude==numero[3]].phrase_2.values[i].lower()) else 0 for som in technique])>0]\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_relou.num_etude)\r\n",
        "print(\"Il y a \",len(numero),\"études vides\")\r\n",
        "k=8\r\n",
        "\r\n",
        "titres=list(base_relou[base_relou.ind_sommaire==1][base_relou.num_etude==numero[k]].phrase_2.values)\\n\",\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),\"\\n\",i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_relou.num_etude)\r\n",
        "index=[i for i in numero if np.sum(base_relou[base_relou.num_etude==i].ind_sommaire)==0]\r\n",
        "base_relou_2=base_relou[[True if base_relou.num_etude[i] in index else False for i in base_relou.index]]\r\n",
        "print(\"Les documents vides tenaces représentent :\",round(len(base_relou_2)/len(base_relou)*100,2),'% des lignes de la base relou')\r\n",
        "print(\"On a réussi à traiter \",round((1-len(np.unique(base_relou_2.num_etude))/len(numero))*100,2),\"% des documents vides initiaux\")\r\n",
        "print(\"Il y a \",len(np.unique(base_relou_2.num_etude)),\"études vides\")\"\r\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero_2=np.unique(base_relou_2.num_etude)\r\n",
        "k=0\r\n",
        "\r\n",
        "titres=list(base_relou_2[base_relou_2.label_k==0][base_relou_2.num_etude==112862].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),\"\\n\",i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "liste=base_relou_2[base_relou_2.label_k==1][base_relou_2.num_etude==101872].phrase_2.values\r\n",
        "s=sommaire(liste)\r\n",
        "print(s)\r\n",
        "#ind_titres(base_relou_2)\r\n",
        "a=light_cleaning(liste[s[0]+1]) #hypothèse donc que le 1er titre vient après le sommaire\r\n",
        "print(a)\r\n",
        "print(''.join([i for i in a]))\r\n",
        "j=indice_relou(liste,s,0.4,0.4)\r\n",
        "j"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "ouais=ind_titres(base_relou_2)\r\n",
        "c=functools.reduce(\r\n",
        "    operator.iconcat,ouais,[])\r\n",
        "print(len(c))\r\n",
        "base_relou_2['ind_sommaire']=c"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_relou_2.num_etude)\r\n",
        "print(\"Il y a \",len(numero),\"études vides\")\r\n",
        "k=9\r\n",
        "\r\n",
        "titres=list(base_relou_2[base_relou_2.ind_sommaire==1][base_relou_2.num_etude==numero[k]].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),\"\\n\",i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_relou_2.num_etude)\r\n",
        "index=[i for i in numero if np.sum(base_relou_2[base_relou_2.num_etude==i].ind_sommaire)==0]\r\n",
        "base_relou_3=base_relou_2[[True if base_relou_2.num_etude[i] in index else False for i in base_relou_2.index]]\r\n",
        "print(\"Les documents vides tenaces représentent :\",round(len(base_relou_3)/len(base_relou_2)*100,2),'% des lignes de la base relou')\r\n",
        "print(\"On a réussi à traiter \",round((1-len(np.unique(base_relou_3.num_etude))/len(numero))*100,2),\"% des documents vides initiaux\")\r\n",
        "print(\"Il y a \",len(np.unique(base_relou_3.num_etude)),\"études vides\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def raffinement_sommaire(base_3,a,b):\r\n",
        "    base=base_3.copy()\r\n",
        "    c=[1 if len(i)>a or len(i)<b else 0 for i in base.phrase_2]#np.zeros(len(base))\r\n",
        "    c_=np.zeros(len(base))\r\n",
        "    for i in range(len(base)):\r\n",
        "        try:\r\n",
        "            k=int(base.phrase_2[i])\r\n",
        "            #print(k)\\n\",\r\n",
        "            c_[i]=1\r\n",
        "        except:\r\n",
        "            continue\r\n",
        "    base['sommaire_longueur']=c\r\n",
        "    base['sommaire_int']=c_\r\n",
        "    return base\r\n",
        "base_=raffinement_sommaire(base_relou,180,3)\r\n",
        "base_.sommaire_int=base_.sommaire_int*base_.ind_sommaire\r\n",
        "base_.sommaire_longueur=base_.sommaire_longueur*base_.ind_sommaire\r\n",
        "base_"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "kmeans=pickle.load(open(\"kmeans_model_new.pickle\",'rb'))\r\n",
        "label_k_relou=kmeans.predict(base_.iloc[:,3:-2])\r\n",
        "base_['label_k']=label_k_relou"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "label_RF_relou=Bagging.predict(base_.iloc[:,3:-1])\r\n",
        "base_['label_RF']=label_RF_relou"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "numero=np.unique(base_.num_etude)\r\n",
        "k=2\r\n",
        "titres=list(base_[base_.label_RF==1][base_.num_etude==numero[k]].phrase_2.values)\r\n",
        "for i in titres:\r\n",
        "    print('\\nIndice :',titres.index(i),i)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import seaborn as sns\r\n",
        "sns.histplot(distrib_nbligne_propre,stat='frequency',bins=100)\r\n"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}